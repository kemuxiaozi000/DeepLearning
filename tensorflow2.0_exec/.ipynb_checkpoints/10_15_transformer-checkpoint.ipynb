{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. preprocessing data\\n\\n2. tools\\n2.1 generates position embedding\\n2.2 create mask (padding, decoder)\\n2.3 scaled_dot_product_attention\\n\\n3.build model\\n3.1 multiheadAttention\\n3.2 EncoderLayer\\n3.3 DecoderLayer\\n3.4 EncoderModel\\n3.5 DecoderModel\\n3.6 Transformer\\n\\n4 train\\n4.1 initialize model\\n4.2 define loss optimizer, learning_rate schedule\\n4.3 train_step\\n4.4 train process\\n\\n6 evalution\\n7 visualize results(attention)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. preprocessing data\n",
    "\n",
    "2. tools\n",
    "2.1 generates position embedding\n",
    "2.2 create mask (padding, decoder)\n",
    "2.3 scaled_dot_product_attention\n",
    "\n",
    "3.build model\n",
    "3.1 multiheadAttention\n",
    "3.2 EncoderLayer\n",
    "3.3 DecoderLayer\n",
    "3.4 EncoderModel\n",
    "3.5 DecoderModel\n",
    "3.6 Transformer\n",
    "\n",
    "4 train\n",
    "4.1 initialize model\n",
    "4.2 define loss optimizer, learning_rate schedule\n",
    "4.3 train_step\n",
    "4.4 train process\n",
    "\n",
    "6 evalution\n",
    "7 visualize results(attention)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n",
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.16.2\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0-beta1\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    version=1.0.0,\n",
      "    description='Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "where one is high resource and the other is low resource.\n",
      "',\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    total_num_examples=54781,\n",
      "    splits={\n",
      "        'test': 1803,\n",
      "        'train': 51785,\n",
      "        'validation': 1193,\n",
      "    },\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "examples, info = tfds.load(\"ted_hrlr_translate/pt_to_en\",\n",
    "                           with_info = True,\n",
    "                          as_supervised = True)\n",
    "train_examples, val_examples = examples[\"train\"], examples[\"validation\"]\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\n",
      "b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'\n",
      "\n",
      "b'mas e se estes fatores fossem ativos ?'\n",
      "b'but what if it were active ?'\n",
      "\n",
      "b'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'\n",
      "b\"but they did n't test for curiosity .\"\n",
      "\n",
      "b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc3\\xa3o pela qual eu , como agn\\xc3\\xb3stica , posso ainda ter f\\xc3\\xa9 .'\n",
      "b'and this conscious defiance is why i , as an agnostic , can still have faith .'\n",
      "\n",
      "b\"`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\"\n",
      "b'you can use everything on the table on me .'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt, en in train_examples.take(5):\n",
    "    print(pt.numpy())\n",
    "    print(en.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转成subword\n",
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt , en in train_examples),\n",
    "    target_vocab_size = 2 ** 13\n",
    ")\n",
    "pt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt , en in train_examples),\n",
    "    target_vocab_size = 2 ** 13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "Origin string is Transformer is awesome.\n",
      "7915 -> 'T'\n",
      "1248 -> 'ran'\n",
      "7946 -> 's'\n",
      "7194 -> 'former '\n",
      "13 -> 'is '\n",
      "2799 -> 'awesome'\n",
      "7877 -> '.'\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"Transformer is awesome.\"\n",
    "tokenized_string = en_tokenizer.encode(sample_string)\n",
    "print(\"Tokenized string is {}\".format(tokenized_string))\n",
    "\n",
    "origin_string = en_tokenizer.decode(tokenized_string)\n",
    "print(\"Origin string is {}\".format(origin_string))\n",
    "\n",
    "# \"{} -> '{}'\" 在内部加一层引号保留空格\n",
    "for token in tokenized_string:\n",
    "    print(\"{} -> '{}'\".format(token, en_tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "# 利用tokenizer将string转成subword并加上起始终止标志符\n",
    "def encode_to_subword(pt_sentence, en_sentence):\n",
    "    # 加上前缀和后缀，相当于<start>\n",
    "    pt_sequence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(pt_sentence.numpy()) \\\n",
    "    + [pt_tokenizer.vocab_size+1]\n",
    "    \n",
    "    en_sequence = [en_tokenizer.vocab_size] \\\n",
    "    + en_tokenizer.encode(en_sentence.numpy()) \\\n",
    "    + [en_tokenizer.vocab_size+1]\n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "# \n",
    "def filter_by_max_length(pt, en):\n",
    "    return tf.logical_and(tf.size(pt) <= max_length, \n",
    "                         tf.size(en) <= max_length)\n",
    "\n",
    "# 封装python函数\n",
    "def tf_encoder_to_subword(pt_sentence, en_sentence):\n",
    "    return tf.py_function(encode_to_subword,\n",
    "                         [pt_sentence, en_sentence],\n",
    "                         [tf.int64, tf.int64])\n",
    "\n",
    "train_dataset = train_examples.map(tf_encoder_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "train_dataset = train_dataset.shuffle(batch_size).padded_batch(\n",
    "    batch_size, padded_shapes=([-1], [-1])) # 在当前两个维度上都取最高的那个值\n",
    "\n",
    "valid_dataset = val_examples.map(tf_encoder_to_subword)\n",
    "valid_dataset = valid_dataset.filter(filter_by_max_length)\n",
    "valid_dataset = valid_dataset.shuffle(batch_size).padded_batch(\n",
    "    batch_size, padded_shapes=([-1], [-1])) # 在当前两个维度上都取最高的那个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 39) (64, 31)\n",
      "(64, 38) (64, 40)\n",
      "(64, 39) (64, 39)\n",
      "(64, 38) (64, 36)\n",
      "(64, 40) (64, 35)\n"
     ]
    }
   ],
   "source": [
    "for pt_batch, en_batch in valid_dataset.take(5):\n",
    "    print(pt_batch.shape, en_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 generates position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# PE (pos,2i) = sin(pos / 10000 ^ (2i/d_model))\n",
    "# PE (pos,2i+1) = cos(pos / 10000 ^ (2i/d_model))\n",
    "# pos [sentence_length, 1]\n",
    "# i.shape : [1,d_model] \n",
    "# result : [sentence_length, d_model]  \n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, 2 *(i//2)/np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def get_position_embedding(sentence_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:, np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis, :],\n",
    "                           d_model)\n",
    "    # sines.shape : [sentence_length, d_model / 2]\n",
    "    # cosenes.shape : [sentence_length, d_model / 2]\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # position_embedding.shape: [sentence_length, d_model]\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = -1)\n",
    "    \n",
    "    # position_embedding.shape: [1,sentence_length, d_model]\n",
    "    position_embedding = position_embedding[np.newaxis, ... ]\n",
    "    \n",
    "    return tf.cast(position_embedding, dtype=tf.float32)\n",
    "\n",
    "position_embedding = get_position_embedding(50,512)\n",
    "print(position_embedding.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0], cmap = \"RdBu\")\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.xlim((0,512))\n",
    "    plt.ylabel(\"Position\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 mask(1.padding mask, 2.look ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=313655, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "x = tf.constant([[7,6,0,0,1], [1,2,3,0,0], [0,0,0,4,5]])\n",
    "create_padding_mask(x)\n",
    "# 并没有取反， 0的时候取1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=313664, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在decode中不让前词看到后词\n",
    "# attention_weights:\n",
    "#  [  [1,2,3],\n",
    "#     [4,5,6],\n",
    "#     [4,5,6] ]\n",
    "# =>\n",
    "#  [  [1,0,0],\n",
    "#     [4,5,0],\n",
    "#     [4,5,6] ]\n",
    "# mask.shape : (seq_len, seq_len)\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask #(seq_len, seq_len)\n",
    "\n",
    "create_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 scaled_dot_product_attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q,k,v,mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - q: shape == (..., seq_len_q, depth)\n",
    "    - k: shape == (..., seq_len_k, depth)\n",
    "    - v: shape == (..., seq_len_v, depth_v)\n",
    "    - seq_len_k == seq_len_v\n",
    "    - mask: shape == (..., seq_len_q, seq_len_k)\n",
    "    Returns:\n",
    "    - output:weighted sum\n",
    "    - attention_weights: weights of attention\n",
    "    \"\"\"\n",
    "    # q和kT要作矩阵乘法， 所以最后一维depth相等\n",
    "    # k和v是key value 对应 \n",
    "    \n",
    "    # shape: (..., seq_len_q, seq_len_k)\n",
    "    matmul_qk = tf.matmul(q,k,transpose_b = True)\n",
    "    \n",
    "    # k 的最后一维depth\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # 为什么加一个很小的数\n",
    "    #  softmax 一个很小的数会无限接近0，mask里为0的地方不会变\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "    # 在seq_len_k维度上做softmax\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    \n",
    "    # shape: (..., seq_len_q, depth_v)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "def print_scaled_dot_product_attention(q,k,v):\n",
    "    temp_out, temp_att = scaled_dot_product_attention(q,k,v,None)\n",
    "    print(\"Attention weights are :\")\n",
    "    print(temp_att)\n",
    "    print(\"Output is : \")\n",
    "    print(temp_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is : \n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q1 = tf.constant([[0,10,0]], dtype = tf.float32) # (1,3)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype = tf.float32) # (4,3)\n",
    "temp_v = tf.constant([[1,0],\n",
    "                      [10,0],\n",
    "                      [100,5],\n",
    "                      [1000,6]], dtype = tf.float32) # (4,2)\n",
    "# 无限接近于0的数打印就是0\n",
    "np.set_printoptions(suppress=True)\n",
    "print_scaled_dot_product_attention(temp_q1,temp_k,temp_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is : \n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q2 = tf.constant([[0,0,10]], dtype = tf.float32) # (1,3)、\n",
    "print_scaled_dot_product_attention(temp_q2,temp_k,temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is : \n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q3 = tf.constant([[10,10,0]], dtype = tf.float32) # (1,3)\n",
    "print_scaled_dot_product_attention(temp_q3,temp_k,temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is : \n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q4 =  tf.constant([[0,0,10],\n",
    "                        [0,10,0],\n",
    "                        [10,10,0]], \n",
    "                        dtype = tf.float32) # (1,3)\n",
    "print_scaled_dot_product_attention(temp_q4,temp_k,temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512)\n",
      "(1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    理论\n",
    "    x -> Wq0 -> q0\n",
    "    x -> Wk0 -> k0\n",
    "    x -> Wv0 -> v0\n",
    "    实际\n",
    "    q -> Wq0 -> q0\n",
    "    k -> Wk0 -> k0\n",
    "    v -> Wv0 -> v0\n",
    "    \n",
    "    q -> Wq -> Q -> split -> q0,q1,q2...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        self.depth =d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)\n",
    "        self.WK = keras.layers.Dense(self.d_model)        \n",
    "        self.WV = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        # 输入之前入果做self_attention shape: (batch_size, seq_len, word_embedding.dims)\n",
    "        # 如果是中间的层次 shape：(batch_size, seq_len, 上一步输出的dim)\n",
    "        q = self.WQ(q) # q.shape: (batch_size, seq_len_q, d_model)\n",
    "        k = self.WK(k) # k.shape: (batch_size, seq_len_kv, d_model)\n",
    "        v = self.WV(v) # v.shape: (batch_size, seq_len_kv, d_model)\n",
    "        \n",
    "        \n",
    "        # q.shape: (batch_size, num_heads, seq_length_q, depth)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        # k.shape: (batch_size, num_heads, seq_length_kv, depth)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        # v.shape: (batch_size, num_heads, seq_length_kv, depth)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # 为何要维度切换\n",
    "        # 因为计算attention地时候用的是后两维去计算\n",
    "        # 所以需要先把num_heads这一维先换到前面去\n",
    "        \n",
    "        \n",
    "        # scaled_attention_outputs.shape : (batch_size, num_heads, seq_length_q, depth)\n",
    "        # attention_weights.shape : (batch_size, num_heads, seq_length_q, seq_length_kv)\n",
    "        scaled_attention_outputs, attention_weights = scaled_dot_product_attention(q,k,v,mask)\n",
    "        \n",
    "        # scaled_attention_outputs.shape : (batch_size, seq_length_q, num_heads, depth)\n",
    "        scaled_attention_outputs = tf.transpose(\n",
    "            scaled_attention_outputs, perm = [0,2,1,3]\n",
    "        )\n",
    "        \n",
    "        # concat_attention.shape : (batch_size, seq_length_q, d_mode)\n",
    "        concat_attention = tf.reshape(scaled_attention_outputs,\n",
    "                                     (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        # x.shape: (batch_size, seq_len, d_model)\n",
    "        # d_model = num_heads * depth\n",
    "        # x -> (batch_size, num_heads, seq_len, self.depth)\n",
    "        \n",
    "        x= tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        # perm 维度交换\n",
    "        return tf.transpose(x, perm=[0,2,1,3])\n",
    "        \n",
    "temp_mha = MultiHeadAttention(d_model = 512, num_heads = 8)\n",
    "y = tf.random.uniform((1,60,256))\n",
    "output, attn = temp_mha(y,y,y,mask = None)\n",
    "print(output.shape)\n",
    "\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model, dff):\n",
    "    # dff : dim of feed_forward_network\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation=\"relu\"),\n",
    "        keras.layers.Dense(d_model)\n",
    "        \n",
    "    ])\n",
    "\n",
    "sample_ffn = feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64,50,512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self_attention -> add & normalize & dropout\n",
    "        -> feed_forward -> add & normalize & dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_normal_1 = keras.layers.LayerNormalization(epsilon= 1e-6)\n",
    "        self.layer_normal_2 = keras.layers.LayerNormalization(epsilon= 1e-6)\n",
    "        \n",
    "        self.dropout_1 = keras.layers.Dropout(rate)\n",
    "        self.dropout_2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "\n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape           : (batch_size, seq_len, dim = d_model) 因为add操作\n",
    "        # attn_output.shape : (batch_size, seq_len, d_model)\n",
    "        attn_output, _ = self.mha(x,x,x,encoder_padding_mask)\n",
    "        attn_output = self.dropout_1(attn_output, training = training)\n",
    "        \n",
    "        # out_1.shape       : (batch_size, seq_len, d_model)\n",
    "        out_1 = self.layer_normal_1(x + attn_output)\n",
    "        \n",
    "        # ffn_output.shape: (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.ffn(out_1)\n",
    "        ffn_output = self.dropout_2(ffn_output, training = training)\n",
    "        out_2 = self.layer_normal_2(out_1 + ffn_output)\n",
    "        \n",
    "        return out_2\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "# 产生均匀分布的随机张量\n",
    "sample_input = tf.random.uniform((64, 50, 512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512)\n",
      "(64, 8, 60, 60)\n",
      "(64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self_attention -> add & normalize & dropout -> out_1\n",
    "    out_1, encoding_outputs -> attention -> add & normalize & dropout -> out_2\n",
    "    out_2  -> feed_forward -> add & normalize & dropout -> out_3\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # 给输入作attention\n",
    "        self.mha_1 = MultiHeadAttention(d_model, num_heads)\n",
    "        # 给encoder和decoder之间做attention\n",
    "        self.mha_2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_normal_1 = keras.layers.LayerNormalization(epsilon= 1e-6)\n",
    "        self.layer_normal_2 = keras.layers.LayerNormalization(epsilon= 1e-6)\n",
    "        self.layer_normal_3 = keras.layers.LayerNormalization(epsilon= 1e-6)\n",
    "        \n",
    "        self.dropout_1 = keras.layers.Dropout(rate)\n",
    "        self.dropout_2 = keras.layers.Dropout(rate)\n",
    "        self.dropout_3 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, encoding_outputs, training, \n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # decoder_mask: 是由look_ahead_mask和decoder_padding_mask混合而来\n",
    "        # x.shape                : (batch_size, target_seq_len, d_model)\n",
    "        # encoding_outputs.shape : (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # attn_1/out_1.shape     : (batch_size, target_seq_len, d_model)\n",
    "        attn_1, attn_weights_1 = self.mha_1(x, x, x, decoder_mask)\n",
    "        attn_1 = self.dropout_1(attn_1, training = training)\n",
    "        out_1 = self.layer_normal_1(attn_1 + x)\n",
    "        \n",
    "        # attn_2/out_2.shape     : (batch_size, target_seq_len, d_model)\n",
    "        attn_2, attn_weights_2 = self.mha_2(out_1, encoding_outputs, encoding_outputs, \n",
    "                                            encoder_decoder_padding_mask)\n",
    "        attn_2 = self.dropout_2(attn_2, training = training)\n",
    "        out_2 = self.layer_normal_1(attn_2 + out_1)\n",
    "        \n",
    "        # ffn_output/out_3.shape: (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out_2)\n",
    "        ffn_output = self.dropout_3(ffn_output, training = training)\n",
    "        out_3 = self.layer_normal_3(out_2 + ffn_output)\n",
    "        \n",
    "        return out_3, attn_weights_1, attn_weights_2\n",
    "\n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_input = tf.random.uniform((64, 60, 512))\n",
    "sample_decoder_output, sample_decoder_attn_weights_1, sample_decoder_attn_weights_2 = sample_decoder_layer(\n",
    "    sample_decoder_input, sample_output, False, None, None)\n",
    "print(sample_decoder_output.shape)\n",
    "print(sample_decoder_attn_weights_1.shape)\n",
    "print(sample_decoder_attn_weights_2.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length,\n",
    "                d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, self.d_model)\n",
    "\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "        # position_embedding.shape     : (1, max_length, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, self.d_model)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                               for _ in range(self.num_layers)]\n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape         : (batch_size, input_seq_len)\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(input_seq_len, self.max_length,\n",
    "                                      \"input_seq_len should <= self.max_length\")\n",
    "        # assert input_seq_len <= self.max_length\n",
    "        \n",
    "        # x.shape    :(batch_size, input_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # embedding 初始化默认从0-1之间取到的，缩放使得x在0-d_model, \n",
    "        # 使x在加上posi_embed之后本身起的作用大一些\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # 维度不对应，第一维1可以自动扩展batch_size份，第二维用切片\n",
    "        x += self.position_embedding[:, :input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "           x =self.encoder_layers[i](x, training, encoder_padding_mask)\n",
    "        \n",
    "        # x.shape: (batch_size, input_seq_len, d_model)\n",
    "        return x\n",
    "    \n",
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64,37))\n",
    "sample_encoder_model_output = sample_encoder_model(\n",
    "    sample_encoder_model_input, \n",
    "    False, encoder_padding_mask = None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.5 DecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "dict_keys(['decoder_layer1_attn_1', 'decoder_layer1_attn_2', 'decoder_layer2_attn_1', 'decoder_layer2_attn_2'])\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length,\n",
    "                d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        \n",
    "        # position_embedding.shape     : (1, max_length, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                               for _ in range(self.num_layers)]\n",
    "    def call(self, x, encoding_outputs, training, \n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # x.shape         : (batch_size, output_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(output_seq_len, self.max_length,\n",
    "                                      \"output_seq_len should <= self.max_length\")\n",
    "        # assert output_seq_len <= self.max_length\n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        # x.shape    :(batch_size, output_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # embedding 初始化默认从0-1之间取到的，缩放使得x在0-d_model, \n",
    "        # 使x在加上posi_embed之后本身起的作用大一些\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # 维度不对应，第一维1可以自动扩展batch_size份，第二维用切片\n",
    "        x += self.position_embedding[:, :output_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, attn_1, attn_2 = self.decoder_layers[i](\n",
    "                x, encoding_outputs, training, \n",
    "                decoder_mask, encoder_decoder_padding_mask)\n",
    "            attention_weights[\n",
    "                \"decoder_layer{}_attn_1\".format(i+1)] = attn_1\n",
    "            attention_weights[\n",
    "                \"decoder_layer{}_attn_2\".format(i+1)] = attn_2\n",
    "        \n",
    "        # x.shape: (batch_size, output_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "    \n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64,35))\n",
    "sample_decoder_model_output, sample_decoder_model_attr= sample_decoder_model(\n",
    "    sample_decoder_model_input,\n",
    "    sample_encoder_model_output,\n",
    "    training = False,\n",
    "    decoder_mask = None,\n",
    "    encoder_decoder_padding_mask = None,\n",
    ")\n",
    "print(sample_decoder_model_output.shape)\n",
    "print(sample_decoder_model_attr.keys())\n",
    "for key in sample_decoder_model_attr:\n",
    "    print(sample_decoder_model_attr[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "decoder_layer1_attn_1 (64, 8, 31, 31)\n",
      "decoder_layer1_attn_2 (64, 8, 31, 26)\n",
      "decoder_layer2_attn_1 (64, 8, 31, 31)\n",
      "decoder_layer2_attn_2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "# 子类api调用继承问提\n",
    "# 仅最后一层大model继承keras.Model, 其他都继承自keras.layers.Layer\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size,\n",
    "                max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_model = EncoderModel(\n",
    "            num_layers, input_vocab_size, max_length,\n",
    "            d_model, num_heads, dff, rate\n",
    "        )\n",
    "        \n",
    "        self.decoder_model = DecoderModel(\n",
    "            num_layers, target_vocab_size, max_length,\n",
    "            d_model, num_heads, dff, rate\n",
    "        )\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "    def call(self, inp, tar, training, encoder_padding_mask, \n",
    "            decoder_mask, encoder_decoder_padding_mask):\n",
    "        # encoding_output.shape: (batch_size, input_seq_len, d_model)\n",
    "        encoding_outputs = self.encoder_model(\n",
    "            inp, training, encoder_padding_mask)\n",
    "        # decoding_outputs.shap： (batch_size, output_seq_len, d_model)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(\n",
    "            tar, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask)\n",
    "        \n",
    "        # prediction.shape: (batch_size, output_seq_len, target_vocab_size)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        \n",
    "        return predictions, attention_weights\n",
    "\n",
    "sample_transformer = Transformer(2, 8500, 8000, max_length, 512, 8, 2048, rate = 0.1)\n",
    "temp_input = tf.random.uniform((64, 26))\n",
    "temp_target = tf.random.uniform((64, 31))\n",
    "\n",
    "predictions, attention_weights = sample_transformer(temp_input,temp_target, training = False,\n",
    "                                                   encoder_padding_mask = None,\n",
    "                                                   decoder_mask = None,\n",
    "                                                   encoder_decoder_padding_mask = None)\n",
    "\n",
    "print(predictions.shape)\n",
    "for key in attention_weights:\n",
    "    print(key, attention_weights[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "# define loss optimizer, learning_rate schedule\n",
    "# train_step\n",
    "# train process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers, \n",
    "                         input_vocab_size,\n",
    "                         target_vocab_size,\n",
    "                         max_length,\n",
    "                         d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 lr & optimizer & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动调整lr\n",
    "# lr = (d_model ** -0.5) * min(step_num ** (-0.5), \n",
    "#                              step_num * warm_up_steps ** (-1.5))\n",
    "\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps = 4000):\n",
    "        super(CustomizedSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** (-1.5))\n",
    "        arg3 = tf.math.rsqrt(self.d_model)\n",
    "         \n",
    "        return arg3 * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate, \n",
    "                                  beta_1 = 0.9, \n",
    "                                  beta_2 = 0.98,\n",
    "                                  epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train step')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomizedSchedule(d_model)\n",
    "\n",
    "plt.plot(\n",
    "    temp_learning_rate_schedule(\n",
    "        tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.xlabel(\"Train step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction = \"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 凡是有padding的地方mask上对应的值都是0\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    \"\"\"\n",
    "    Encoder:\n",
    "        - encoder_padding_mask (self attention of EncoderLayer)\n",
    "    Decoder:\n",
    "        - look_ahead_mask (self attention of DecoderLayer)\n",
    "        - encoder_decoder_padding_mask (en-decoder attention of DecoderLayer)\n",
    "        - decoder_padding_mask (self attention of DecoderLayer)\n",
    "    \"\"\"\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    # 作用在同一层的mask合并（与操作）\n",
    "    decoder_mask = tf.maximum(decoder_padding_mask,\n",
    "                             look_ahead_mask)\n",
    "#     print(encoder_padding_mask.shape)\n",
    "#     print(encoder_decoder_padding_mask.shape)\n",
    "#     print(look_ahead_mask.shape)\n",
    "#     print(decoder_padding_mask.shape)\n",
    "#     print(decoder_mask.shape)\n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inp, temp_tar = iter(train_dataset.take(1)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38)\n",
      "(64, 39)\n",
      "(64, 1, 1, 38)\n",
      "(64, 1, 1, 38)\n",
      "(39, 39)\n",
      "(64, 1, 1, 39)\n",
      "(64, 1, 39, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=319518, shape=(64, 1, 1, 38), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=319550, shape=(64, 1, 39, 39), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=319525, shape=(64, 1, 1, 38), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_inp.shape)\n",
    "print(temp_tar.shape)\n",
    "create_masks(temp_inp, temp_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.3044 Acc 0.2056\n",
      "Epoch 1 Batch 200 Loss 1.4826 Acc 0.2179\n",
      "Epoch 1 Batch 400 Loss 1.4699 Acc 0.2217\n",
      "Epoch 1 Batch 600 Loss 1.4513 Acc 0.2252\n",
      "Epoch 1  Loss 1.4388 Acc 0.2270\n",
      "Time take for 1 epoch: 652.9913294315338 secs \n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1689 Acc 0.2212\n",
      "Epoch 2 Batch 200 Loss 1.2980 Acc 0.2390\n",
      "Epoch 2 Batch 400 Loss 1.2821 Acc 0.2434\n",
      "Epoch 2 Batch 600 Loss 1.2636 Acc 0.2470\n",
      "Epoch 2  Loss 1.2536 Acc 0.2486\n",
      "Time take for 1 epoch: 66.16948676109314 secs \n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.9997 Acc 0.2459\n",
      "Epoch 3 Batch 200 Loss 1.1393 Acc 0.2586\n",
      "Epoch 3 Batch 400 Loss 1.1295 Acc 0.2623\n",
      "Epoch 3 Batch 600 Loss 1.1162 Acc 0.2653\n",
      "Epoch 3  Loss 1.1084 Acc 0.2666\n",
      "Time take for 1 epoch: 65.98498272895813 secs \n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8937 Acc 0.2615\n",
      "Epoch 4 Batch 200 Loss 1.0228 Acc 0.2733\n",
      "Epoch 4 Batch 400 Loss 1.0167 Acc 0.2763\n",
      "Epoch 4 Batch 600 Loss 1.0080 Acc 0.2789\n",
      "Epoch 4  Loss 1.0026 Acc 0.2800\n",
      "Time take for 1 epoch: 65.6142749786377 secs \n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.8026 Acc 0.2689\n",
      "Epoch 5 Batch 200 Loss 0.9396 Acc 0.2834\n",
      "Epoch 5 Batch 400 Loss 0.9341 Acc 0.2867\n",
      "Epoch 5 Batch 600 Loss 0.9277 Acc 0.2890\n",
      "Epoch 5  Loss 0.9242 Acc 0.2898\n",
      "Time take for 1 epoch: 65.16360759735107 secs \n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7302 Acc 0.2747\n",
      "Epoch 6 Batch 200 Loss 0.8694 Acc 0.2932\n",
      "Epoch 6 Batch 400 Loss 0.8669 Acc 0.2957\n",
      "Epoch 6 Batch 600 Loss 0.8606 Acc 0.2981\n",
      "Epoch 6  Loss 0.8576 Acc 0.2989\n",
      "Time take for 1 epoch: 65.70624279975891 secs \n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6826 Acc 0.2887\n",
      "Epoch 7 Batch 200 Loss 0.8114 Acc 0.3010\n",
      "Epoch 7 Batch 400 Loss 0.8118 Acc 0.3032\n",
      "Epoch 7 Batch 600 Loss 0.8078 Acc 0.3052\n",
      "Epoch 7  Loss 0.8050 Acc 0.3060\n",
      "Time take for 1 epoch: 65.67316770553589 secs \n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.6344 Acc 0.2870\n",
      "Epoch 8 Batch 200 Loss 0.7670 Acc 0.3067\n",
      "Epoch 8 Batch 400 Loss 0.7656 Acc 0.3093\n",
      "Epoch 8 Batch 600 Loss 0.7636 Acc 0.3111\n",
      "Epoch 8  Loss 0.7611 Acc 0.3119\n",
      "Time take for 1 epoch: 65.52465033531189 secs \n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.5947 Acc 0.2952\n",
      "Epoch 9 Batch 200 Loss 0.7271 Acc 0.3126\n",
      "Epoch 9 Batch 400 Loss 0.7257 Acc 0.3152\n",
      "Epoch 9 Batch 600 Loss 0.7230 Acc 0.3171\n",
      "Epoch 9  Loss 0.7216 Acc 0.3177\n",
      "Time take for 1 epoch: 66.53709959983826 secs \n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.5989 Acc 0.2932\n",
      "Epoch 10 Batch 200 Loss 0.6890 Acc 0.3181\n",
      "Epoch 10 Batch 400 Loss 0.6892 Acc 0.3204\n",
      "Epoch 10 Batch 600 Loss 0.6876 Acc 0.3222\n",
      "Epoch 10  Loss 0.6868 Acc 0.3227\n",
      "Time take for 1 epoch: 66.48265385627747 secs \n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.5546 Acc 0.3047\n",
      "Epoch 11 Batch 200 Loss 0.6564 Acc 0.3234\n",
      "Epoch 11 Batch 400 Loss 0.6576 Acc 0.3253\n",
      "Epoch 11 Batch 600 Loss 0.6563 Acc 0.3271\n",
      "Epoch 11  Loss 0.6551 Acc 0.3277\n",
      "Time take for 1 epoch: 66.05320644378662 secs \n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.5040 Acc 0.3117\n",
      "Epoch 12 Batch 200 Loss 0.6272 Acc 0.3270\n",
      "Epoch 12 Batch 400 Loss 0.6284 Acc 0.3295\n",
      "Epoch 12 Batch 600 Loss 0.6279 Acc 0.3311\n",
      "Epoch 12  Loss 0.6271 Acc 0.3316\n",
      "Time take for 1 epoch: 66.03435611724854 secs \n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4978 Acc 0.3100\n",
      "Epoch 13 Batch 200 Loss 0.6036 Acc 0.3309\n",
      "Epoch 13 Batch 400 Loss 0.6053 Acc 0.3333\n",
      "Epoch 13 Batch 600 Loss 0.6045 Acc 0.3348\n",
      "Epoch 13  Loss 0.6033 Acc 0.3353\n",
      "Time take for 1 epoch: 66.03999352455139 secs \n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4696 Acc 0.3162\n",
      "Epoch 14 Batch 200 Loss 0.5784 Acc 0.3347\n",
      "Epoch 14 Batch 400 Loss 0.5817 Acc 0.3367\n",
      "Epoch 14 Batch 600 Loss 0.5818 Acc 0.3382\n",
      "Epoch 14  Loss 0.5809 Acc 0.3388\n",
      "Time take for 1 epoch: 65.64852833747864 secs \n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.4667 Acc 0.3092\n",
      "Epoch 15 Batch 200 Loss 0.5588 Acc 0.3382\n",
      "Epoch 15 Batch 400 Loss 0.5620 Acc 0.3400\n",
      "Epoch 15 Batch 600 Loss 0.5612 Acc 0.3417\n",
      "Epoch 15  Loss 0.5603 Acc 0.3422\n",
      "Time take for 1 epoch: 66.05460739135742 secs \n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.4694 Acc 0.3072\n",
      "Epoch 16 Batch 200 Loss 0.5416 Acc 0.3405\n",
      "Epoch 16 Batch 400 Loss 0.5436 Acc 0.3428\n",
      "Epoch 16 Batch 600 Loss 0.5428 Acc 0.3445\n",
      "Epoch 16  Loss 0.5421 Acc 0.3451\n",
      "Time take for 1 epoch: 65.63802695274353 secs \n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.4393 Acc 0.3187\n",
      "Epoch 17 Batch 200 Loss 0.5247 Acc 0.3432\n",
      "Epoch 17 Batch 400 Loss 0.5254 Acc 0.3456\n",
      "Epoch 17 Batch 600 Loss 0.5251 Acc 0.3474\n",
      "Epoch 17  Loss 0.5246 Acc 0.3479\n",
      "Time take for 1 epoch: 65.4111475944519 secs \n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4164 Acc 0.3232\n",
      "Epoch 18 Batch 200 Loss 0.5082 Acc 0.3459\n",
      "Epoch 18 Batch 400 Loss 0.5100 Acc 0.3482\n",
      "Epoch 18 Batch 600 Loss 0.5096 Acc 0.3500\n",
      "Epoch 18  Loss 0.5091 Acc 0.3505\n",
      "Time take for 1 epoch: 67.52350187301636 secs \n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.4077 Acc 0.3273\n",
      "Epoch 19 Batch 200 Loss 0.4937 Acc 0.3480\n",
      "Epoch 19 Batch 400 Loss 0.4959 Acc 0.3506\n",
      "Epoch 19 Batch 600 Loss 0.4953 Acc 0.3523\n",
      "Epoch 19  Loss 0.4949 Acc 0.3529\n",
      "Time take for 1 epoch: 66.59448719024658 secs \n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.4054 Acc 0.3265\n",
      "Epoch 20 Batch 200 Loss 0.4790 Acc 0.3509\n",
      "Epoch 20 Batch 400 Loss 0.4815 Acc 0.3533\n",
      "Epoch 20 Batch 600 Loss 0.4813 Acc 0.3548\n",
      "Epoch 20  Loss 0.4805 Acc 0.3555\n",
      "Time take for 1 epoch: 66.23629236221313 secs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='3'\n",
    "\n",
    "train_loss = keras.metrics.Mean(name = \"train_loss\")\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = \"train_accuracy\")\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    # 把tar_inp 输入给decoder, 预测target_real是否正确\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask = create_masks(inp, \n",
    "                                                                                    tar_inp )\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, True,\n",
    "                                    encoder_padding_mask,\n",
    "                                    decoder_mask,\n",
    "                                    encoder_decoder_padding_mask)\n",
    "        \n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "    \n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 200 == 0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f} Acc {:.4f}\".format(\n",
    "                epoch + 1, batch, train_loss.result(), \n",
    "                train_accuracy.result()))\n",
    "            \n",
    "    print(\"Epoch {}  Loss {:.4f} Acc {:.4f}\".format(\n",
    "                epoch + 1, \n",
    "        train_loss.result(), \n",
    "                train_accuracy.result()))\n",
    "    print(\"Time take for 1 epoch: {} secs \\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\\\n",
    "eg:     A B C D -> E F G\n",
    "train:  A B C D, E F G ->F G H\n",
    "eval:   A B C D -> E\n",
    "        A B C D, E -> F\n",
    "        A B C D, E F -> G\n",
    "        A B C D, E F G -> H\n",
    "\"\"\"\n",
    "def evaluate(inp_sentence):\n",
    "    input_id_sentence = [pt_tokenizer.vocab] \\\n",
    "                        + pt_tokenizer.encode(inp_sentence) \\\n",
    "                        + [pt_tokenizer.vocab + 1]\n",
    "    #encoder_input.shape: (1, input_sentence_length)\n",
    "    encoder_input = tf.expand_dims(input_id_sentence, 0)\n",
    "    \n",
    "    # decoder_input.shape: (1,1)\n",
    "    decoder_input = tf.expand_dims([en_tokenizer.vocab_size], 0)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask = create_masks(\n",
    "            encoder_input, decoder_input)\n",
    "        \n",
    "        #  predictions.shape: (batch_size, output_target_len, target_vocab_size)\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input,\n",
    "            decoder_input,\n",
    "            False,\n",
    "            encoder_padding_mask,\n",
    "            decoder_mask,\n",
    "            encoder_decoder_padding_mask)\n",
    "        # 当单步输出用\n",
    "        predictions = predictions[:, -1 ,:]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis= -1),\n",
    "                              tf.int32)\n",
    "        if tf.equal(predicted_id, en_tokenizer.vocab_size +1):\n",
    "            return tf.squeeze(decoder_input, axis = 0), attention_weights\n",
    "        \n",
    "        decoder_input = tf.concat([decoder_input, predicted_id], axis = -1)\n",
    "    return tf.squeeze(decoder_input, axis = 0), attention_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoder_decoder_attention(attention, input_sentence,\n",
    "                                  result, layer_name):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    input_id_sentence = pt_tokenizer.encoder(input_sentence)\n",
    "    \n",
    "    # attention[layer_name].shape: (batch_size = 1, num_heads, tar_len. input_len)\n",
    "    attention = tf.squeeze(attention[layer_name], axis = 0)\n",
    "    \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_plot(2, 4, head+1)\n",
    "        # 做切片， 因为到最后<end>，就直接返回了，attention并未放到矩阵里\n",
    "        ax.matshow(attention[head][:-1, :])\n",
    "        fontdict = {\"fontsize\":10}\n",
    "        # x轴锚点数目\n",
    "        ax.set_xticks(range(len(input_id_sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "                      \n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        ax.set_xticklabels([\"<start>\"] + [pt_tokenizer.decoder([i]) for i in input_id_sentence],\n",
    "                         fontdict=fontdict, rotation = 90)\n",
    "        # 排除start end\n",
    "        ax.set_yticklabel([en_tokenizer.decoder([i]) for i in result if i < en_tokenizer.vocab_size],\n",
    "                         fontdict=fontdict, rotation = 90)\n",
    "        ax.set_xlabel(\"Head {}\".format(head +1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence, layer_name = \"\"):\n",
    "    result, attention_weights = evaluate(input_sentence)\n",
    "    \n",
    "    predicted_sentence = en_tokenizer.decoder(\n",
    "            [i for i in result if i < en_tokenizer.vocab_size])\n",
    "    print(\"Input : {}\".format(input_sentence))\n",
    "    print(\"Predicted translation : {}\".format(predicted_sentence))\n",
    "    \n",
    "    if layer_name:\n",
    "        plot_encoder_decoder_attention(attention_weights, input_sentence,\n",
    "                                      result, layer_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
