{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. preprocessing data\\n2. build model\\n2.1 encoder\\n2.2 attention\\n2.3 decoder\\n2.4 optimizer & loss\\n2.5 train\\n3.evalution\\n3.1 given sentence, return translated result\\n3.2 visualize results(attention)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. preprocessing data\n",
    "2. build model\n",
    "2.1 encoder\n",
    "2.2 attention\n",
    "2.3 decoder\n",
    "2.4 optimizer & loss\n",
    "2.5 train\n",
    "3.evalution\n",
    "3.1 given sentence, return translated result\n",
    "3.2 visualize results(attention)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n",
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.16.2\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0-beta1\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put it on\n",
      "Poneoslo\n"
     ]
    }
   ],
   "source": [
    "en_spa_file_path = \"./data/spa-eng/spa.txt\"\n",
    "\n",
    "import unicodedata\n",
    "# 转成asc是为了减小词表\n",
    "def unicode_to_ascii(s):\n",
    "    # NFD 如果有一个unicode是多个asc组成的，就把这个拆开， Mn 重音\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\",s) if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "en_sentence = \"Put it on\"\n",
    "sp_sentence = \"Ponéoslo\"\n",
    "# 比如é 是一个e和一个重音符号，分开因为重音符号是Mn，所以忽略 所以é => e\n",
    "print(unicode_to_ascii(en_sentence))\n",
    "print(unicode_to_ascii(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> put it on <end>\n",
      "<start> poneoslo <end>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_sentence(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    # []任意一个， （）替换操作, \\1 本身\n",
    "    # 标点符号前后加空格\n",
    "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
    "    # 多余空格变成一个空格\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    # 除了标点符号和字母以外都是空格\n",
    "    s = re.sub(r'[^a-zA-Z?.!,¿]+', \" \", s)\n",
    "    # 去掉前后空格\n",
    "    s = s.rstrip().strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s\n",
    "\n",
    "def make_list(x,y):\n",
    "    return [x,y]\n",
    "\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
      "<start> puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboracion . sin embargo , si animamos a los miembros a contribuir frases en sus propios idiomas en lugar de experimentar con los idiomas que estan aprendiendo , podriamos ser capaces de minimizar los errores . <end>\n"
     ]
    }
   ],
   "source": [
    "def parse_data(filename):\n",
    "    lines = open(filename, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n",
    "    sentence_pairs = [line.split(\"\\t\")[0:-1] for line in lines]\n",
    "    preprocessed_sentence_pairs = [ (preprocess_sentence(en),preprocess_sentence(sp)) for en, sp  in sentence_pairs]\n",
    "    return zip(*preprocessed_sentence_pairs)\n",
    "en_dataset, sp_dataset = parse_data(en_spa_file_path)\n",
    "print(en_dataset[-1])\n",
    "print(sp_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2) (3, 4) (5, 6)\n",
      "(1, 3, 5) (2, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "# 补充\n",
    "a = [(1,2), (3,4),(5,6)]\n",
    "# 单星号能够将这个变量拆分成单个元素\n",
    "print(*a)\n",
    "# zip可以转置\n",
    "c,d = zip(*a)\n",
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 11\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16, 16] [11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "# 文本式数据要被model读取要变成id式\n",
    "def tokenizer(lang):\n",
    "    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n",
    "        num_words = None, filters=\"\", split=\" \"\n",
    "    )\n",
    "    \n",
    "    lang_tokenizer.fit_on_texts(lang) \n",
    "    #序列的列表，列表中每个序列对应于一段输入文本 \n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang) #得到词索引[[1, 2, 3, 4], [1, 2, 3, 5]]\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                   padding = \"post\")\n",
    "    return tensor, lang_tokenizer\n",
    "input_tensor, input_tokenizer = tokenizer(sp_dataset[0:30000])\n",
    "output_tensor, output_tokenizer = tokenizer(en_dataset[0:30000])\n",
    "\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def len_test(tensor):\n",
    "    return [len(t) for t in tensor[0:10]]\n",
    "\n",
    "max_length_input = max_length(input_tensor)\n",
    "max_length_output = max_length(output_tensor)\n",
    "\n",
    "print(max_length_input, max_length_output)\n",
    "print(len_test(input_tensor), len_test(output_tensor))\n",
    "# dir(input_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 6000, 24000, 6000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切分训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_eval, output_train, output_eval = train_test_split(input_tensor, \n",
    "                                                                      output_tensor, test_size=0.2)\n",
    "\n",
    "len(input_train), len(input_eval), len(output_train), len(output_eval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> <start>\n",
      "5 --> ¿\n",
      "22 --> por\n",
      "11 --> que\n",
      "16 --> esta\n",
      "1125 --> enfadada\n",
      "4 --> ?\n",
      "2 --> <end>\n",
      "\n",
      "1 --> <start>\n",
      "79 --> why\n",
      "25 --> are\n",
      "5 --> you\n",
      "187 --> angry\n",
      "6 --> ?\n",
      "2 --> <end>\n"
     ]
    }
   ],
   "source": [
    "# 验证tokenizer是否起作用\n",
    "def convert(example, tokenizer):\n",
    "    for t in example:\n",
    "        if t != 0:\n",
    "            print(\"%d --> %s\" %(t, tokenizer.index_word[t]))\n",
    "\n",
    "convert(input_train[1], input_tokenizer)\n",
    "print()\n",
    "convert(output_train[1], output_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(input_tensor, output_tensor, \n",
    "                 batch_size, epochs, shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, \n",
    "                                                 output_tensor))\n",
    "    if shuffle:\n",
    "        dataset.shuffle(30000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size, \n",
    "                                           drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "    \n",
    "train_dataset = make_dataset(input_train, output_train,\n",
    "                             batch_size, epochs, True)\n",
    "eval_dataset = make_dataset(input_eval, output_eval,\n",
    "                             batch_size, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n",
      "tf.Tensor(\n",
      "[[   1   42  349 ...    0    0    0]\n",
      " [   1    5   22 ...    0    0    0]\n",
      " [   1    5   22 ...    0    0    0]\n",
      " ...\n",
      " [   1    6 3489 ...    0    0    0]\n",
      " [   1  438  208 ...    0    0    0]\n",
      " [   1 1033 3996 ...    0    0    0]], shape=(64, 16), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[   1   28   24  406    3    2    0    0    0    0    0]\n",
      " [   1   79   25    5  187    6    2    0    0    0    0]\n",
      " [   1   79   25    5  187    6    2    0    0    0    0]\n",
      " [   1   27   12  519   21  669    3    2    0    0    0]\n",
      " [   1   53  283   18  624    3    2    0    0    0    0]\n",
      " [   1  464   18   10 3930    3    2    0    0    0    0]\n",
      " [   1   77   31   52    6    2    0    0    0    0    0]\n",
      " [   1    4   16  131  629    3    2    0    0    0    0]\n",
      " [   1    4  236   15   64    5    3    2    0    0    0]\n",
      " [   1    8    9  211  195   60    6    2    0    0    0]\n",
      " [   1    7 1952    3    2    0    0    0    0    0    0]\n",
      " [   1   32   10  233 1435   37    2    0    0    0    0]\n",
      " [   1   27   12    5   35  430    6    2    0    0    0]\n",
      " [   1   17   85   12  519   48    3    2    0    0    0]\n",
      " [   1   31  128   70   63   82    3    2    0    0    0]\n",
      " [   1    4   85   12   22    9  155    3    2    0    0]\n",
      " [   1  117  169  170   18    3    2    0    0    0    0]\n",
      " [   1  143    9   68    5   35    3    2    0    0    0]\n",
      " [   1    9   11   84  457    3    2    0    0    0    0]\n",
      " [   1    9   11   34   21   83    3    2    0    0    0]\n",
      " [   1   17   43   32    5   40    3    2    0    0    0]\n",
      " [   1    4   92   41  184    3    2    0    0    0    0]\n",
      " [   1    7  227 1720    3    2    0    0    0    0    0]\n",
      " [   1    8   46   10  359 1884    6    2    0    0    0]\n",
      " [   1  171  123  282    3    2    0    0    0    0    0]\n",
      " [   1   14    8   49  338    3    2    0    0    0    0]\n",
      " [   1   61   71   75   63   39    3    2    0    0    0]\n",
      " [   1  103  535    3    2    0    0    0    0    0    0]\n",
      " [   1  464   47   36    3    2    0    0    0    0    0]\n",
      " [   1   64    5   58  108    2    0    0    0    0    0]\n",
      " [   1  171   55  150  119    3    2    0    0    0    0]\n",
      " [   1  132   32    5   45    3    2    0    0    0    0]\n",
      " [   1   60   11   10  757   39    3    2    0    0    0]\n",
      " [   1    9   26  300   70  196    3    2    0    0    0]\n",
      " [   1    5   24   84 4634   90    3    2    0    0    0]\n",
      " [   1   54   52   42  172  570    3    2    0    0    0]\n",
      " [   1  308   13  488    3    2    0    0    0    0    0]\n",
      " [   1   51  167   22    5 3081    6    2    0    0    0]\n",
      " [   1    9   11   34   10  419    3    2    0    0    0]\n",
      " [   1    4  760   14   26   39    3    2    0    0    0]\n",
      " [   1   56   25    5    6    2    0    0    0    0    0]\n",
      " [   1    4   45   15 1136 4753    3    2    0    0    0]\n",
      " [   1    5   77   41 1035    3    2    0    0    0    0]\n",
      " [   1   23    4  158  282    6    2    0    0    0    0]\n",
      " [   1   14  181  336    3    2    0    0    0    0    0]\n",
      " [   1    5  290    3    2    0    0    0    0    0    0]\n",
      " [   1    4   38  171    7    3    2    0    0    0    0]\n",
      " [   1   27   12   41  202   42    7    3    2    0    0]\n",
      " [   1   19    8 2233    3    2    0    0    0    0    0]\n",
      " [   1    4   57   10  725    3    2    0    0    0    0]\n",
      " [   1  549  733    8  206    3    2    0    0    0    0]\n",
      " [   1   31  302   47   10  376    3    2    0    0    0]\n",
      " [   1   22    5   33   15 1401    6    2    0    0    0]\n",
      " [   1    5   24   35  406    3    2    0    0    0    0]\n",
      " [   1    4   27   12  241   86  167    3    2    0    0]\n",
      " [   1   19   11 1565    3    2    0    0    0    0    0]\n",
      " [   1   22    5   29   10   83    6    2    0    0    0]\n",
      " [   1   53 1165   20  222    3    2    0    0    0    0]\n",
      " [   1   17   24   13  284    3    2    0    0    0    0]\n",
      " [   1  179 1105    3    2    0    0    0    0    0    0]\n",
      " [   1    4  118  201    3    2    0    0    0    0    0]\n",
      " [   1    7 1481   46    3    2    0    0    0    0    0]\n",
      " [   1    4   29   66  261    3    2    0    0    0    0]\n",
      " [   1    4  800 2616    3    2    0    0    0    0    0]], shape=(64, 11), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9403\n",
      "4834\n"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "embedding_units = 256\n",
    "units = 1024\n",
    "input_vocab_size = len(input_tokenizer.word_index)+1\n",
    "output_vocab_size = len(output_tokenizer.word_index)+1\n",
    "\n",
    "print(input_vocab_size)\n",
    "print(output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_output.shape: (64, 16, 1024)\n",
      "sample_hidden.shape: (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n",
    "    # 使用super().__init__()手动执行父类的构造方法, \n",
    "    # 不然会由于子类重写父类的__init__的方法导致父类在构造方法中定义的默认属性无法继承（不能使用）\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        # embedding将大型稀疏向量转换为保留语义关系的低维空间\n",
    "        self.embedding = keras.layers.Embedding(vocab_size,\n",
    "                                                embedding_units)\n",
    "        self.gru = keras.layers.GRU(self.encoding_units, \n",
    "                                    return_sequences= True,\n",
    "                                   return_state = True,\n",
    "                                   recurrent_initializer=\"glorot_uniform\")\n",
    "    def call(self, x, hidden):\n",
    "        # 函数式调用\n",
    "        # a Layer instance is callable on a tensor , and returns a tensor \n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x,initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoding_units))\n",
    "encoder = Encoder(input_vocab_size, embedding_units,\n",
    "                  units, batch_size )\n",
    "# encoder.tr\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "\n",
    "print(\"sample_output.shape:\", sample_output.shape)\n",
    "print(\"sample_hidden.shape:\", sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_results.shape: (64, 1024)\n",
      "attention_weights.shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_hidden, encoder_outputs):\n",
    "        # dencoder_hidden.shape: (batch_size, units)\n",
    "        # encoder_outputs.shape: (batch_size, length, units)\n",
    "        \n",
    "        # before V: (batch_size, length, units)\n",
    "        # after V: (batch_size, length, 1)\n",
    "        # tf.expand_dims:在指定索引出增加一维度，值为1，从索引0开始\n",
    "        # axis: 取值范围是[-阶数，阶数]，二维的时候0指的是列，1指的是行，\n",
    "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
    "        \n",
    "        # shape: (batch_size, length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # 加权\n",
    "        # context_vector.shape: (batch_size, length, units)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        \n",
    "        # 平均  在length 维度上求和\n",
    "        #  context_vector.shape: (batch_size, units)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_model = BahdanauAttention(units = 10)\n",
    "attention_results, attention_weights = attention_model(sample_hidden, sample_output)\n",
    "print(\"attention_results.shape:\", attention_results.shape)\n",
    "print(\"attention_weights.shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output.shape: (64, 4834)\n",
      "decoder_hidden.shape: (64, 1024)\n",
      "decoder_attention_weights.shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                   return_sequences = True,\n",
    "                                   return_state = True,\n",
    "                                   recurrent_initializer = \"glorot_uniform\")\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "        \n",
    "    def call(self, x, hidden, encoding_outputs):\n",
    "        # context_vector,.shape: (batch_size, units)\n",
    "        context_vector, attention_weights = self.attention(hidden, \n",
    "                                                           encoding_outputs)\n",
    "        # before embedding: x.shape(batch_size, 1)\n",
    "        # after embedding: x.shape(batch_size, 1, embedding_units)\n",
    "        x = self.embedding(x)\n",
    "        combined_x = tf.concat([tf.expand_dims(context_vector, 1),x], axis = -1)\n",
    "        \n",
    "        # output.shape: [batch_size, 1, decoding_units]\n",
    "        # state.shape: [batch_size, decoding_units]\n",
    "        output, state = self.gru(combined_x)\n",
    "        \n",
    "        # output.shape: [batch_size, decoding_units]\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output.shape: [batch_size, vocab_size]\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output, state, attention_weights\n",
    "    \n",
    "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
    "outputs = decoder(tf.random.uniform((batch_size, 1)),\n",
    "                 sample_hidden,\n",
    "                 sample_output)\n",
    "decoder_output, decoder_hidden, decoder_attention_weights = outputs\n",
    "print(\"decoder_output.shape:\", decoder_output.shape)\n",
    "print(\"decoder_hidden.shape:\", decoder_hidden.shape)\n",
    "print(\"decoder_attention_weights.shape:\", decoder_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "# 要从这么多词语id中预测出哪一个是正确的词语id , 所以是分类问题\n",
    "# 分类问题用SparseCategoricalCrossentropy\n",
    "# from_logits = True, 是因为最后是fc, 没有加任何激活函数\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
    "  from_logits = True, reduction = \"none\"\n",
    ")\n",
    "def loss_function(real, pred):\n",
    "  # 把padding对应的损失函数去掉\n",
    "  # tf.math.equal(real, 0) 是padding的部分值都为1，再取反\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, encoding_hidden):\n",
    "  loss = 0\n",
    "  with tf.GradientTape() as tape:\n",
    "    encoding_outputs, encoding_hidden = encoder(\n",
    "      inp, encoding_hidden\n",
    "    )\n",
    "    decoding_hidden = encoding_hidden\n",
    "\n",
    "    # eg. <start> I am here <end>\n",
    "    # 1. <start> -> I\n",
    "    # 2. I -> am\n",
    "    # 3. am -> here\n",
    "    # 4.here -> <end>\n",
    "    for t in range(0, targ.shape[1]-1):\n",
    "      decoding_input  = tf.expand_dims(targ[:, t], 1)\n",
    "      predictions, decoding_hidden, _ = decoder(\n",
    "        decoding_input, decoding_hidden, encoding_outputs\n",
    "      )\n",
    "      loss += loss_function(targ[:, t+1], predictions)\n",
    "  # 如果不求平均的话， 设不同的batch_size, 得到的损失函数结果不一样\n",
    "  batch_loss = loss / int(targ.shape[0])\n",
    "  #   a = [1,2,3]\n",
    "  # b = [4,5,6]\n",
    "  # c = a+b\n",
    "  # c的结果：[1,2,3,4,5,6]\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_step at 0x0000017B8E07F158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x0000017B8E07F158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function train_step at 0x0000017B8E07F158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x0000017B8E07F158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000017B8DF14BF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000017B8DF14BF8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000017B8DF14BF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000017B8DF14BF8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function train_step at 0x0000017B8E07F158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x0000017B8E07F158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function train_step at 0x0000017B8E07F158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x0000017B8E07F158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Encoder.call of <__main__.Encoder object at 0x0000017B82266320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x0000017B8D9EA2B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BahdanauAttention.call of <__main__.BahdanauAttention object at 0x0000017B8D9C20F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_gru at 0x0000017B81CA7378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_gru at 0x0000017B81CA7378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_gru at 0x0000017B81CA7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_gru at 0x0000017B81CA7620>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Epoch 1 Batch 0 Loss 0.8077\n",
      "Epoch 1 Batch 100 Loss 0.3809\n",
      "Epoch 1 Batch 200 Loss 0.3176\n",
      "Epoch 1 Batch 300 Loss 0.2895\n",
      "Epoch 1 Batch 400 Loss 0.2612\n",
      "Epoch 1 Loss 0.3290\n",
      "Time take for 1 epoch 55.25418472290039 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2484\n",
      "Epoch 2 Batch 100 Loss 0.2397\n",
      "Epoch 2 Batch 200 Loss 0.2086\n",
      "Epoch 2 Batch 300 Loss 0.2080\n",
      "Epoch 2 Batch 400 Loss 0.1678\n",
      "Epoch 2 Loss 0.2038\n",
      "Time take for 1 epoch 38.509668827056885 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1453\n",
      "Epoch 3 Batch 100 Loss 0.1594\n",
      "Epoch 3 Batch 200 Loss 0.1403\n",
      "Epoch 3 Batch 300 Loss 0.1449\n",
      "Epoch 3 Batch 400 Loss 0.0871\n",
      "Epoch 3 Loss 0.1249\n",
      "Time take for 1 epoch 38.74967288970947 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0779\n",
      "Epoch 4 Batch 100 Loss 0.0996\n",
      "Epoch 4 Batch 200 Loss 0.0932\n",
      "Epoch 4 Batch 300 Loss 0.0966\n",
      "Epoch 4 Batch 400 Loss 0.0431\n",
      "Epoch 4 Loss 0.0753\n",
      "Time take for 1 epoch 38.90376305580139 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0352\n",
      "Epoch 5 Batch 100 Loss 0.0561\n",
      "Epoch 5 Batch 200 Loss 0.0620\n",
      "Epoch 5 Batch 300 Loss 0.0670\n",
      "Epoch 5 Batch 400 Loss 0.0252\n",
      "Epoch 5 Loss 0.0471\n",
      "Time take for 1 epoch 39.03914022445679 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0175\n",
      "Epoch 6 Batch 100 Loss 0.0352\n",
      "Epoch 6 Batch 200 Loss 0.0427\n",
      "Epoch 6 Batch 300 Loss 0.0499\n",
      "Epoch 6 Batch 400 Loss 0.0177\n",
      "Epoch 6 Loss 0.0310\n",
      "Time take for 1 epoch 39.00602102279663 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0106\n",
      "Epoch 7 Batch 100 Loss 0.0221\n",
      "Epoch 7 Batch 200 Loss 0.0272\n",
      "Epoch 7 Batch 300 Loss 0.0347\n",
      "Epoch 7 Batch 400 Loss 0.0128\n",
      "Epoch 7 Loss 0.0222\n",
      "Time take for 1 epoch 38.99439549446106 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0062\n",
      "Epoch 8 Batch 100 Loss 0.0170\n",
      "Epoch 8 Batch 200 Loss 0.0254\n",
      "Epoch 8 Batch 300 Loss 0.0240\n",
      "Epoch 8 Batch 400 Loss 0.0111\n",
      "Epoch 8 Loss 0.0167\n",
      "Time take for 1 epoch 39.02867913246155 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0069\n",
      "Epoch 9 Batch 100 Loss 0.0131\n",
      "Epoch 9 Batch 200 Loss 0.0183\n",
      "Epoch 9 Batch 300 Loss 0.0171\n",
      "Epoch 9 Batch 400 Loss 0.0089\n",
      "Epoch 9 Loss 0.0133\n",
      "Time take for 1 epoch 39.06570744514465 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0046\n",
      "Epoch 10 Batch 100 Loss 0.0100\n",
      "Epoch 10 Batch 200 Loss 0.0139\n",
      "Epoch 10 Batch 300 Loss 0.0145\n",
      "Epoch 10 Batch 400 Loss 0.0100\n",
      "Epoch 10 Loss 0.0107\n",
      "Time take for 1 epoch 39.007203102111816 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "epochs = 10\n",
    "steps_per_epoch = len(input_tensor) // batch_size\n",
    "# 第一个for遍历10次数据集\n",
    "# 第二个for遍历一次\n",
    "for epoch in range(epochs):\n",
    "  start = time.time()\n",
    "\n",
    "  encoding_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for( batch, (inp, targ)) in enumerate(\n",
    "      train_dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, encoding_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print(\"Epoch {} Batch {} Loss {:.4f}\".format(\n",
    "              epoch + 1, batch, batch_loss.numpy()))\n",
    "\n",
    "  print(\"Epoch {} Loss {:.4f}\".format(\n",
    "          epoch + 1, total_loss / steps_per_epoch))\n",
    "  print(\"Time take for 1 epoch {} sec\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_sentence):\n",
    "  attention_matrix = np.zeros((max_length_output, max_length_input))\n",
    "  input_sentence = preprocess_sentence(input_sentence)\n",
    "    \n",
    "  # text to id\n",
    "  inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(\" \")]\n",
    "  # padding\n",
    "  inputs = keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen = max_length_input, padding=\"post\")\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  results = \"\"\n",
    "#   encodng_hidden = encoder.initialize_hidden_state()\n",
    "  encoding_hidden = tf.zeros((1, units))\n",
    "\n",
    "  encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden)\n",
    "  decoding_hidden = encoding_hidden\n",
    "\n",
    "  # eg: <start> -> A\n",
    "  # A -> B -> C -> D\n",
    "\n",
    "  #decoding_input.shape: (1,1)\n",
    "  decoding_input = tf.expand_dims(\n",
    "    [output_tokenizer.word_index[\"<start>\"]], 0\n",
    "  )\n",
    "\n",
    "  for t in range(max_length_output):\n",
    "    # 上一步的输出作为下一步的输入\n",
    "    predictions, decoding_hidden, attention_weights = decoder(\n",
    "      decoding_input, decoding_hidden, encoding_outputs\n",
    "    )\n",
    "    # 把每一步的attention_weights 保存到attention_matrix， 代表输入和输出的关系\n",
    "    # attention_weights.shape: (batch_size, inputs_length, 1) (1,16,1)\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_matrix[t] = attention_weights.numpy()\n",
    "\n",
    "    # predictions.shape: (batch_size, vocab_size)  (1,4935)\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    results += output_tokenizer.index_word[predicted_id] + \" \"\n",
    "    \n",
    "    if output_tokenizer.index_word[predicted_id] == \"<end>\":\n",
    "        return results, input_sentence, attention_matrix\n",
    "    \n",
    "    decoding_input = tf.expand_dims([predicted_id], 0)\n",
    "  return results, input_sentence, attention_matrix\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention_matrix, input_sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention_matrix, cmap = \"viridis\")\n",
    "    \n",
    "    font_dict = {\"fontsize\" : 14}\n",
    "    ax.set_xticklabels([\"\"] + input_sentence, fontdict = font_dict, rotation = 90)\n",
    "    ax.set_yticklabels([\"\"] + predicted_sentence, fontdict = font_dict)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "    results, input_sentence, attention_matrix = evaluate(input_sentence)\n",
    "    \n",
    "    print(\"Input: %s\" % (input_sentence))\n",
    "    print(\"Predicted translation: %s\" % (results))\n",
    "    \n",
    "    attention_matrix = attention_matrix[:len(results.split(\" \")),\n",
    "                                        :len(results.split(\" \"))]\n",
    "    plot_attention(attention_matrix, input_sentence.split(\" \"),\n",
    "                  results.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hoy hace mucho frio . <end>\n",
      "Predicted translation: it is very cold today . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u\"Hoy hace mucho frío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'usuarios'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a627ef8e6c25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"El número de usuarios de las aplicaciones aumentó considerablemente durante el período de la epidemia.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-5f36ac7d4f4f>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted translation: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-0c6399011175>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# text to id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[1;31m# padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   inputs = keras.preprocessing.sequence.pad_sequences(\n",
      "\u001b[1;32m<ipython-input-21-0c6399011175>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# text to id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[1;31m# padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   inputs = keras.preprocessing.sequence.pad_sequences(\n",
      "\u001b[1;31mKeyError\u001b[0m: 'usuarios'"
     ]
    }
   ],
   "source": [
    "translate(u\"El número de usuarios de las aplicaciones aumentó considerablemente durante el período de la epidemia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
