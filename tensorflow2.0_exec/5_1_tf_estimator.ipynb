{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    keras 转 estimator\\n    使用预定义的estimator\\n        BaselineClassifier\\n        LinearClassifier\\n        DNNClassifier\\n    Tf.feature_column 做特征工程\\n    \\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    keras 转 estimator\n",
    "    使用预定义的estimator\n",
    "        BaselineClassifier\n",
    "        LinearClassifier\n",
    "        DNNClassifier\n",
    "    Tf.feature_column 做特征工程\n",
    "    \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "    sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0  male  35.0                   0      0   8.0500  Third  unknown   \n",
      "1  male  54.0                   0      0  51.8625  First        E   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval =  eval_df.pop(\"survived\")\n",
    "\n",
    "print(train_df.head(2))\n",
    "print(eval_df.head(2))\n",
    "print(y_train.head(2))\n",
    "print(y_eval.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c9712080b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAVQElEQVR4nO3df4zc9X3n8ef7TEoTNsePQvdcQ7tE\ncmnBbtx6RdNyinZD2zhJFZJe0xqRyL5w3USiuvQO6c6kVZM2QkJ3+XGRaNpzCgc9cl44fiQUkjbI\nZY/2VJp6KYntgBMIPmrD2Qk4djaJUE3e/WO+KyabWe/OfGd2vvvh+ZBWM/P5fr/zfTEeXvvdz3xn\nJjITSVJZ/sWwA0iS+s9yl6QCWe6SVCDLXZIKZLlLUoFOG3YAgHPPPTfHxsa62ubb3/42Z5xxxmAC\n1WCu7jU1W1NzQXOzNTUXNDdbnVyzs7PfyMzzOi7MzFP+ABcADwKPAfuB91Xj5wAPAF+tLs9u2+Y6\n4AngAPDGpfaxefPm7NaDDz7Y9TYrwVzda2q2pubKbG62pubKbG62OrmAPblIry5nWuYkcG1m/jTw\nOuCaiLgY2AHszsz1wO7qNtWyrcAlwBbgExGxpstfSJKkGpYs98x8NjMfqa5/i9YR/DrgCuDWarVb\ngbdV168ApjPzhcx8itYR/KX9Di5JWlxkF+9QjYgx4CFgA/B0Zp7VtuxYZp4dETcCD2fmbdX4TcDn\nMvPOBfc1BUwBjI6Obp6enu4q+NzcHCMjI11tsxLM1b2mZmtqLmhutqbmguZmq5NrcnJyNjPHOy5c\nbL5m4Q8wAswCv1bd/uaC5ceqyz8C3tk2fhPwb0513865D15Tc2U2N1tTc2U2N1tTc2U2N9sw59yJ\niFcAdwGfysy7q+EjEbG2Wr4WOFqNH6L1Iuy884FnlrMfSVJ/LFnuERG0jr4fy8yPti26F9hWXd8G\nfKZtfGtEnB4RFwLrgS/0L7IkaSnLOc/9MuBdwN6IeLQaez9wA3BHRFwNPA28AyAz90fEHcCXaZ1p\nc01mvtj35JKkRS1Z7pn5N0AssvjyRba5Hri+Ri5JUg1+/IAkFagRHz+g1WNsx/09b3vwhrf0MYmk\nU/HIXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkF\nstwlqUCWuyQVyHKXpAJZ7pJUoOV8QfbNEXE0Iva1jd0eEY9WPwfnv1s1IsYi4rtty/5kkOElSZ0t\n55uYbgFuBP5sfiAzf3P+ekR8BDjetv6TmbmpXwElSd1bzhdkPxQRY52WRUQAvwG8ob+xJEl1RGYu\nvVKr3O/LzA0Lxl8PfDQzx9vW2w98BTgB/F5m/vUi9zkFTAGMjo5unp6e7ir43NwcIyMjXW2zEkrP\ntffw8aVXWsTGdWd2HC/9MRuEpmZrai5obrY6uSYnJ2fn+3ehul+QfSWwq+32s8CPZ+ZzEbEZ+HRE\nXJKZJxZumJk7gZ0A4+PjOTEx0dWOZ2Zm6HablVB6ru11viD7qs77L/0xG4SmZmtqLmhutkHl6vls\nmYg4Dfg14Pb5scx8ITOfq67PAk8CP1k3pCSpO3VOhfwl4PHMPDQ/EBHnRcSa6vprgPXA1+pFlCR1\nazmnQu4C/ha4KCIORcTV1aKtfP+UDMDrgS9FxBeBO4H3Zubz/QwsSVracs6WuXKR8e0dxu4C7qof\nS5JUh+9QlaQCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5\nS1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUoOV8h+rNEXE0Iva1jX0wIg5HxKPVz5vbll0X\nEU9ExIGIeOOggkuSFrecI/dbgC0dxj+WmZuqn88CRMTFtL44+5Jqm09ExJp+hZUkLc+S5Z6ZDwHP\nL/P+rgCmM/OFzHwKeAK4tEY+SVIPIjOXXiliDLgvMzdUtz8IbAdOAHuAazPzWETcCDycmbdV690E\nfC4z7+xwn1PAFMDo6Ojm6enproLPzc0xMjLS1TYrofRcew8f73nbjevO7Dhe+mM2CE3N1tRc0Nxs\ndXJNTk7OZuZ4p2Wn9Zjnj4EPAVldfgR4NxAd1u342yMzdwI7AcbHx3NiYqKrADMzM3S7zUooPdf2\nHff3vO3Bqzrvv/THbBCamq2puaC52QaVq6ezZTLzSGa+mJnfAz7JS1Mvh4AL2lY9H3imXkRJUrd6\nKveIWNt28+3A/Jk09wJbI+L0iLgQWA98oV5ESVK3lpyWiYhdwARwbkQcAj4ATETEJlpTLgeB9wBk\n5v6IuAP4MnASuCYzXxxMdEnSYpYs98y8ssPwTadY/3rg+jqhJEn1+A5VSSqQ5S5JBbLcJalAlrsk\nFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KB\nLHdJKtCS5R4RN0fE0YjY1zb2XyPi8Yj4UkTcExFnVeNjEfHdiHi0+vmTQYaXJHW2nCP3W4AtC8Ye\nADZk5s8AXwGua1v2ZGZuqn7e25+YkqRuLFnumfkQ8PyCsc9n5snq5sPA+QPIJknqUWTm0itFjAH3\nZeaGDsv+HLg9M2+r1ttP62j+BPB7mfnXi9znFDAFMDo6unl6erqr4HNzc4yMjHS1zUooPdfew8d7\n3nbjujM7jpf+mA1CU7M1NRc0N1udXJOTk7OZOd5p2Wl1QkXE7wIngU9VQ88CP56Zz0XEZuDTEXFJ\nZp5YuG1m7gR2AoyPj+fExERX+56ZmaHbbVZC6bm277i/520PXtV5/6U/ZoPQ1GxNzQXNzTaoXD2f\nLRMR24BfBa7K6vA/M1/IzOeq67PAk8BP9iOoJGn5eir3iNgC/GfgrZn5nbbx8yJiTXX9NcB64Gv9\nCCpJWr4lp2UiYhcwAZwbEYeAD9A6O+Z04IGIAHi4OjPm9cAfRsRJ4EXgvZn5fMc7liQNzJLlnplX\ndhi+aZF17wLuqhtKklSP71CVpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QC\nWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklSgJcs9Im6OiKMRsa9t7JyI\neCAivlpdnt227LqIeCIiDkTEGwcVXJK0uOUcud8CbFkwtgPYnZnrgd3VbSLiYmArcEm1zSciYk3f\n0kqSlmXJcs/Mh4DnFwxfAdxaXb8VeFvb+HRmvpCZTwFPAJf2KaskaZkiM5deKWIMuC8zN1S3v5mZ\nZ7UtP5aZZ0fEjcDDmXlbNX4T8LnMvLPDfU4BUwCjo6Obp6enuwo+NzfHyMhIV9ushNJz7T18vOdt\nN647s+N46Y/ZIDQ1W1NzQXOz1ck1OTk5m5njnZadVivVD4oOYx1/e2TmTmAnwPj4eE5MTHS1o5mZ\nGbrdZiWUnmv7jvt73vbgVZ33X/pjNghNzdbUXNDcbIPK1evZMkciYi1AdXm0Gj8EXNC23vnAM73H\nkyT1otdyvxfYVl3fBnymbXxrRJweERcC64Ev1IsoSerWktMyEbELmADOjYhDwAeAG4A7IuJq4Gng\nHQCZuT8i7gC+DJwErsnMFweUXZK0iCXLPTOvXGTR5Yusfz1wfZ1QkqR6fIeqJBXIcpekAlnuklQg\ny12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLc\nJalAlrskFchyl6QCLfk1e4uJiIuA29uGXgP8PnAW8FvA16vx92fmZ3tOKEnqWs/lnpkHgE0AEbEG\nOAzcA/xb4GOZ+eG+JJQkda1f0zKXA09m5v/r0/1JkmqIzKx/JxE3A49k5o0R8UFgO3AC2ANcm5nH\nOmwzBUwBjI6Obp6enu5qn3Nzc4yMjNRM3n+l59p7+HjP225cd2bH8dIfs0Foaram5oLmZquTa3Jy\ncjYzxzstq13uEfFDwDPAJZl5JCJGgW8ACXwIWJuZ7z7VfYyPj+eePXu62u/MzAwTExO9hR6g0nON\n7bi/520P3vCWjuOlP2aD0NRsTc0Fzc1WJ1dELFru/ZiWeROto/YjAJl5JDNfzMzvAZ8ELu3DPiRJ\nXehHuV8J7Jq/ERFr25a9HdjXh31IkrrQ89kyABHxKuCXgfe0Df+XiNhEa1rm4IJlkqQVUKvcM/M7\nwI8sGHtXrUSSpNp8h6okFchyl6QCWe6SVCDLXZIKVOsFVa1Odd6IJGl18MhdkgpkuUtSgSx3SSqQ\n5S5JBbLcJalAlrskFchTIbViFjsF89qNJ9k+4NMzF/ssealUHrlLUoEsd0kqkOUuSQWy3CWpQL6g\nugr18tkwK/GipaTmqPs1eweBbwEvAiczczwizgFuB8Zofc3eb2TmsXoxJUnd6Me0zGRmbsrM8er2\nDmB3Zq4Hdle3JUkraBBz7lcAt1bXbwXeNoB9SJJOITKz940jngKOAQn898zcGRHfzMyz2tY5lpln\nd9h2CpgCGB0d3Tw9Pd3Vvufm5hgZGek5+6CsRK69h493vc3oK+HIdwcQpg9WItvGdWd2vU1Tn2PQ\n3GxNzQXNzVYn1+Tk5GzbrMn3qfuC6mWZ+UxE/CjwQEQ8vtwNM3MnsBNgfHw8JyYmutrxzMwM3W6z\nElYiVy8vjF678SQf2dvM189XItvBqya63qapzzFobram5oLmZhtUrlrTMpn5THV5FLgHuBQ4EhFr\nAarLo3VDSpK603O5R8QZEfHq+evArwD7gHuBbdVq24DP1A0pSepOnb+FR4F7ImL+fv5XZv5FRPw9\ncEdEXA08DbyjfkxJUjd6LvfM/Brw2g7jzwGX1wklSarHjx+QpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ\n5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQVq5veuSX021uNXE27fcT8H\nb3jLABJJg+WRuyQVyHKXpAJZ7pJUoJ7n3CPiAuDPgH8FfA/YmZkfj4gPAr8FfL1a9f2Z+dm6QaXV\nqJe5/nnO9auOOi+ongSuzcxHIuLVwGxEPFAt+1hmfrh+PElSL+p8QfazwLPV9W9FxGPAun4FkyT1\nLjKz/p1EjAEPARuA/whsB04Ae2gd3R/rsM0UMAUwOjq6eXp6uqt9zs3NMTIyUif2QKxErr2Hj3e9\nzegr4ch3BxCmD5qabT7XxnVn9nwfvfxbzTvVfl/Oz/9eNTVbnVyTk5OzmTneaVntco+IEeD/ANdn\n5t0RMQp8A0jgQ8DazHz3qe5jfHw89+zZ09V+Z2ZmmJiYAJo1r9mea1B6PWf7I3ub+baGpmabz1Xn\nOTKo5+ZKPM960dRc0NxsdXJFxKLlXuv/qIh4BXAX8KnMvBsgM4+0Lf8kcF+dfUgvV6f6xTD/BqvF\n+GKsej4VMiICuAl4LDM/2ja+tm21twP7eo8nSepFnSP3y4B3AXsj4tFq7P3AlRGxida0zEHgPbUS\nFqrOn+taWf5baTWqc7bM3wDRYZHntEvSkPkOVUkqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12S\nCmS5S1KBLHdJKlDzPopvFen0tvSlPtBJWg16/ciFazeeZKK/UdQjj9wlqUCWuyQVyHKXpAK97Ofc\n/ThXSSV62Ze7pP5q0tdevpw5LSNJBbLcJalATstIBXo5vpa01H/zqd6DUuJ00MDKPSK2AB8H1gB/\nmpk3DGpfksrwcvylNCgDmZaJiDXAHwFvAi6m9aXZFw9iX5KkHzSoI/dLgScy82sAETENXAF8eUD7\nk6ShqfMXxy1bzuhjkpdEZvb/TiN+HdiSmf+uuv0u4Ocz87fb1pkCpqqbFwEHutzNucA3+hC338zV\nvaZma2ouaG62puaC5mark+snMvO8TgsGdeQeHca+77dIZu4Edva8g4g9mTne6/aDYq7uNTVbU3NB\nc7M1NRc0N9ugcg3qVMhDwAVtt88HnhnQviRJCwyq3P8eWB8RF0bEDwFbgXsHtC9J0gIDmZbJzJMR\n8dvAX9I6FfLmzNzf5930PKUzYObqXlOzNTUXNDdbU3NBc7MNJNdAXlCVJA2XHz8gSQWy3CWpQKuu\n3CNiS0QciIgnImLHkLPcHBFHI2Jf29g5EfFARHy1ujx7CLkuiIgHI+KxiNgfEe9rQraI+OGI+EJE\nfLHK9QdNyNWWb01E/ENE3NewXAcjYm9EPBoRe5qSLSLOiog7I+Lx6rn2Cw3JdVH1WM3/nIiI32lI\ntv9QPff3RcSu6v+JgeRaVeXewI81uAXYsmBsB7A7M9cDu6vbK+0kcG1m/jTwOuCa6nEadrYXgDdk\n5muBTcCWiHhdA3LNex/wWNvtpuQCmMzMTW3nQzch28eBv8jMnwJeS+uxG3quzDxQPVabgM3Ad4B7\nhp0tItYB/x4Yz8wNtE422TqwXJm5an6AXwD+su32dcB1Q840Buxru30AWFtdXwscaMDj9hngl5uU\nDXgV8Ajw803IReu9GLuBNwD3NenfEjgInLtgbKjZgH8JPEV1UkZTcnXI+SvA/21CNmAd8I/AObTO\nVLyvyjeQXKvqyJ2XHpx5h6qxJhnNzGcBqssfHWaYiBgDfhb4OxqQrZr6eBQ4CjyQmY3IBfw34D8B\n32sba0IuaL27+/MRMVt9bEcTsr0G+DrwP6qprD+NiDMakGuhrcCu6vpQs2XmYeDDwNPAs8DxzPz8\noHKttnJf8mMN9JKIGAHuAn4nM08MOw9AZr6YrT+XzwcujYgNw84UEb8KHM3M2WFnWcRlmflztKYj\nr4mI1w87EK0jz58D/jgzfxb4NsOdtvoB1Rso3wr872FnAajm0q8ALgR+DDgjIt45qP2ttnJfDR9r\ncCQi1gJUl0eHESIiXkGr2D+VmXc3KRtAZn4TmKH1msWwc10GvDUiDgLTwBsi4rYG5AIgM5+pLo/S\nmju+tAHZDgGHqr+8AO6kVfbDztXuTcAjmXmkuj3sbL8EPJWZX8/MfwLuBn5xULlWW7mvho81uBfY\nVl3fRmu+e0VFRAA3AY9l5kebki0izouIs6rrr6T1ZH982Lky87rMPD8zx2g9p/4qM9857FwAEXFG\nRLx6/jqtOdp9w86Wmf8f+MeIuKgaupzWR3oP/TFrcyUvTcnA8LM9DbwuIl5V/T96Oa0XoQeTa5gv\ndvT4osSbga8ATwK/O+Qsu2jNnf0TrSOZq4EfofXC3Fery3OGkOtf05qu+hLwaPXz5mFnA34G+Icq\n1z7g96vxoT9mbRkneOkF1aHnojW3/cXqZ//8c74h2TYBe6p/z08DZzchV5XtVcBzwJltY0PPBvwB\nrQOafcD/BE4fVC4/fkCSCrTapmUkSctguUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QC/TP6VtbU\nsKDTiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c97434e550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNMIAQCMMADTCAEDzf0WdIOqrm0/iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind =\"barh\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c974387710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"class\"].value_counts().plot(kind =\"barh\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c974418da0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD4CAYAAAAkRnsLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAANeUlEQVR4nO3dfazdBX3H8fdHCnWCFrQ4OxzrrGxM\neRgKTIkh4AgDGi0MdA4i6ojELWMzC0bmIiFjbmxuCS5OWcMcW2JGtgznAwgzILrwNNoNKAgoE+ZA\nEsPQ8tCFCf3uj3M6rk0fzqXf83Bv36+k8Z6eX3/3c097fd9zftdrqgpJkjq8aNoDJEmLh1GRJLUx\nKpKkNkZFktTGqEiS2iyZ9oBpWr58ea1cuXLaMyRpQVm/fv1jVbX/tu7braOycuVK1q1bN+0ZkrSg\nJPnP7d3ny1+SpDZGRZLUxqhIktoYFUlSG6MiSWpjVCRJbYyKJKmNUZEktTEqkqQ2RkWS1MaoSJLa\nGBVJUhujIklqY1QkSW2MiiSpjVGRJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1R\nkSS1MSqSpDZGRZLUZsm0B0zThkc2svKCq6c9Y+Y9dMnqaU+QtED4TEWS1MaoSJLaGBVJUhujIklq\nY1QkSW2MiiSpjVGRJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZG\nRZLUxqhIktoYFUlSG6MiSWpjVCRJbYyKJKmNUZEktVnQUUlyXJIvTXuHJGlgQUdFkjRbph6VJCuT\n3Jfk8iR3J/lskhOS3JTkW0mOHv66Ocm/D//zZ7dxnr2TfCbJ7cPj1kzj45Gk3dnUozL0WuATwGHA\nwcCZwFuA84GPAPcBx1bVEcCFwB9u4xy/B9xQVUcBxwMfT7L31gclOTfJuiTrntu0cSwfjCTtrpZM\ne8DQg1W1ASDJPcD1VVVJNgArgWXA3yQ5CChgz22c40Tg7UnOH95+MXAgcO/cg6pqLbAWYOmKg2oM\nH4sk7bZmJSrPzHl785zbmxlsvBj4alWdlmQlcOM2zhHg9Kq6f3wzJUk7Misvf+3MMuCR4dvv3c4x\n1wHnJQlAkiMmsEuSNMdCicqfAH+U5CZgj+0cczGDl8XuSnL38LYkaYJStfteVli64qBa8Z5Lpz1j\n5j10yeppT5A0Q5Ksr6ojt3XfQnmmIklaAIyKJKmNUZEktTEqkqQ2RkWS1MaoSJLaGBVJUhujIklq\nY1QkSW2MiiSpjVGRJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZG\nRZLUZsm0B0zToQcsY90lq6c9Q5IWDZ+pSJLaGBVJUhujIklqY1QkSW2MiiSpjVGRJLUxKpKkNkZF\nktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZGRZLUxqhIktoYFUlSG6MiSWpjVCRJ\nbYyKJKnNSFFJcnGSJXNuvyzJX49vliRpIRr1mcoS4LYkhyU5EbgdWD++WZKkhWjJzg+BqvrdJNcD\ntwHfB46tqgfGukyStOCM+vLXscAngN8HbgQ+meQnxrhLkrQAjfRMBfhT4B1V9Q2AJL8M3AAcPK5h\nkqSFZ9SovLmqnttyo6quSvK1MW2SJC1Qo16oX57kr5JcC5DkdcCp45slSVqIRo3KFcB1wIrh7W8C\nHxzHIEnSwjXyM5Wq+ntgM0BVPQs8t+M/Ikna3YwalaeTvAIogCRvAjaObZUkaUEa9UL97wBfAFYl\nuQnYHzhjbKskSQvSqM9UVgEnA8cwuLbyLUYPkiRpNzFqVD5aVU8A+wEnAGuBT49tlSRpQRo1Klsu\nyq8GLquqzwN7jWeSJGmhGjUqjyT5S+CdwDVJls7jz0qSdhOjhuGdDK6lnFRVPwBeDnxobKskSQvS\nqD+leBNw1ZzbjwKPjmuUJGlh8iUsSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZGRZLUxqhIktoY\nFUlSG6MiSWpjVCRJbYyKJKmNUZEktTEqkqQ2RkWS1Gak/z+VxWrDIxtZecHV054hSRP10CWrx3Zu\nn6lIktoYFUlSG6MiSWpjVCRJbYyKJKmNUZEktTEqkqQ2RkWS1MaoSJLaGBVJUhujIklqY1QkSW2M\niiSpjVGRJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZji0qS30py\nb5LPjun8FyU5fxznliS9MEvGeO7fAE6uqgfH+D4kSTNkLFFJchnwGuALSa4EVgGHDt/fRVX1+STv\nBU4F9gAOAf4M2At4N/AMcEpVPZ7k/cC5w/seAN5dVZu2en+rgL8A9gc2Ae+vqvvG8bFJkrZvLC9/\nVdUHgO8CxwN7AzdU1VHD2x9Psvfw0EOAM4GjgY8Bm6rqCOAW4OzhMVdV1VFVdThwL3DONt7lWuC8\nqnojcD7wqe1tS3JuknVJ1j23aeOufqiSpDnG+fLXFicCb59z/ePFwIHDt79aVU8CTybZCHxx+Psb\ngMOGbx+S5A+AfYF9gOvmnjzJPsAxwD8k2fLbS7c3pqrWMogQS1ccVLvwcUmStjKJqAQ4varu/5Hf\nTH6BwctcW2yec3vznG1XAKdW1Z3Dl8yO2+r8LwJ+UFU/3ztbkjRfk/iW4uuA8zJ8GpHkiHn++ZcC\njybZEzhr6zur6gngwSTvGJ4/SQ7fxc2SpBdgElG5GNgTuCvJ3cPb8/FR4DbgK8D2Lr6fBZyT5E7g\nHmDNC9wqSdoFqdp9LyssXXFQrXjPpdOeIUkT9dAlq3fpzydZX1VHbus+/xf1kqQ2RkWS1MaoSJLa\nGBVJUhujIklqY1QkSW2MiiSpjVGRJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1R\nkSS1MSqSpDZGRZLUxqhIktoYFUlSG6MiSWpjVCRJbZZMe8A0HXrAMtZdsnraMyRp0fCZiiSpjVGR\nJLUxKpKkNkZFktTGqEiS2hgVSVIboyJJamNUJEltjIokqY1RkSS1MSqSpDZGRZLUxqhIktoYFUlS\nG6MiSWpjVCRJbYyKJKmNUZEktTEqkqQ2RkWS1MaoSJLaGBVJUhujIklqY1QkSW2MiiSpjVGRJLVJ\nVU17w9QkeRK4f9o7dmI58Ni0R+yEG3fdrO8DN3ZZDBt/qqr239YdS8azZ8G4v6qOnPaIHUmyzo27\nbtY3zvo+cGOXxb7Rl78kSW2MiiSpze4elbXTHjACN/aY9Y2zvg/c2GVRb9ytL9RLknrt7s9UJEmN\njIokqc2ij0qSk5Lcn+SBJBds4/4k+fPh/XclecMMbjw4yS1Jnkly/qT3jbjxrOHjd1eSm5McPoMb\n1wz33ZFkXZK3zNrGOccdleS5JGdMct/wfe/scTwuycbh43hHkgtnbeOcnXckuSfJ12ZtY5IPzXkM\n7x7+fb98xjYuS/LFJHcOH8f37fSkVbVofwF7AP8BvAbYC7gTeN1Wx5wCfBkI8Cbgthnc+ErgKOBj\nwPkz+jgeA+w3fPvkGX0c9+H564iHAffN2sY5x90AXAOcMWsbgeOAL0363+E8N+4LfAM4cHj7lbO2\ncavj3wbcMGsbgY8Afzx8e3/gcWCvHZ13sT9TORp4oKq+XVX/C1wJrNnqmDXA39bArcC+SVbM0saq\n+l5V3Q78cIK75hpl481V9f3hzVuBV8/gxqdq+NkB7A1M+rtURvn3CHAe8I/A9yY5bmjUjdM0ysYz\ngauq6jsw+ByawY1z/SrwdxNZ9rxRNhbw0iRh8EXZ48CzOzrpYo/KAcB/zbn98PD35nvMOE37/Y9i\nvhvPYfDsb5JG2pjktCT3AVcDvzahbVvsdGOSA4DTgMsmuGuuUf+u3zx8SeTLSV4/mWn/b5SNPwPs\nl+TGJOuTnD2xdQMjf84keQlwEoMvJCZplI2fBH4O+C6wAfjtqtq8o5Mu9h/Tkm383tZfnY5yzDhN\n+/2PYuSNSY5nEJVJX68YaWNVfQ74XJJjgYuBE8Y9bI5RNl4KfLiqnht8cThxo2z8NwY/++mpJKcA\n/wQcNPZlzxtl4xLgjcAvAj8G3JLk1qr65rjHDc3n8/ptwE1V9fgY92zLKBt/CbgDeCuwCvhKkn+p\nqie2d9LF/kzlYeAn59x+NYPizveYcZr2+x/FSBuTHAZcDqypqv+e0LYt5vU4VtXXgVVJlo972Byj\nbDwSuDLJQ8AZwKeSnDqZecAIG6vqiap6avj2NcCeM/g4PgxcW1VPV9VjwNeBSX7zyHz+Pb6Lyb/0\nBaNtfB+DlxGrqh4AHgQO3uFZJ3lhaNK/GHy18m3gp3n+QtTrtzpmNT96of5fZ23jnGMvYjoX6kd5\nHA8EHgCOmeG/69fy/IX6NwCPbLk9Kxu3Ov4KJn+hfpTH8VVzHsejge/M2uPI4CWb64fHvgS4Gzhk\nljYOj1vG4DrF3pP8e57H4/hp4KLh2z8+/JxZvqPzLuqXv6rq2SS/CVzH4DsdPlNV9yT5wPD+yxh8\nh80pDP4LcRODMs/UxiSvAtYBLwM2J/kgg+/S2O5T0ElvBC4EXsHgK2uAZ2uCP4l1xI2nA2cn+SHw\nP8Cv1PCzZYY2TtWIG88Afj3Jswwex3fN2uNYVfcmuRa4C9gMXF5Vd8/SxuGhpwH/XFVPT2rbPDde\nDFyRZAODL7w/XINnftvlj2mRJLVZ7NdUJEkTZFQkSW2MiiSpjVGRJLUxKpKkNkZFktTGqEiS2vwf\n76gf6WdW+lEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df,y_train],axis = 1).groupby(\"sex\").survived.mean().plot(kind =\"barh\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# feature_column\n",
    "categorical_columns = [\"sex\", \"n_siblings_spouses\", \"parch\", \n",
    "                       \"class\", \"deck\", \"embark_town\", \"alone\"]\n",
    "numeric_columns = [\"age\",\"fare\" ]\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    # 离散特征作成one-hot编码\n",
    "    onehot_describe = tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            categorical_column, vocab))\n",
    "    feature_columns.append(onehot_describe)\n",
    "    \n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(numeric_column, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0      male  22.0                   1      0   7.2500   Third  unknown   \n",
      "1    female  38.0                   1      0  71.2833   First        C   \n",
      "2    female  26.0                   0      0   7.9250   Third  unknown   \n",
      "3    female  35.0                   1      0  53.1000   First        C   \n",
      "4      male  28.0                   0      0   8.4583   Third  unknown   \n",
      "..      ...   ...                 ...    ...      ...     ...      ...   \n",
      "622    male  28.0                   0      0  10.5000  Second  unknown   \n",
      "623    male  25.0                   0      0   7.0500   Third  unknown   \n",
      "624  female  19.0                   0      0  30.0000   First        B   \n",
      "625  female  28.0                   1      2  23.4500   Third  unknown   \n",
      "626    male  32.0                   0      0   7.7500   Third  unknown   \n",
      "\n",
      "     embark_town alone  \n",
      "0    Southampton     n  \n",
      "1      Cherbourg     n  \n",
      "2    Southampton     y  \n",
      "3    Southampton     n  \n",
      "4     Queenstown     y  \n",
      "..           ...   ...  \n",
      "622  Southampton     y  \n",
      "623  Southampton     y  \n",
      "624  Southampton     y  \n",
      "625  Southampton     n  \n",
      "626   Queenstown     y  \n",
      "\n",
      "[627 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10,# 数据集遍历多少次 ， \n",
    "                 shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "         (dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=89, shape=(5,), dtype=string, numpy=array([b'male', b'male', b'female', b'male', b'female'], dtype=object)>, 'age': <tf.Tensor: id=81, shape=(5,), dtype=float64, numpy=array([39., 36., 34., 19., 24.])>, 'n_siblings_spouses': <tf.Tensor: id=87, shape=(5,), dtype=int32, numpy=array([0, 1, 1, 0, 0])>, 'parch': <tf.Tensor: id=88, shape=(5,), dtype=int32, numpy=array([0, 2, 1, 0, 0])>, 'fare': <tf.Tensor: id=86, shape=(5,), dtype=float64, numpy=array([24.15  , 27.75  , 32.5   ,  8.05  , 83.1583])>, 'class': <tf.Tensor: id=83, shape=(5,), dtype=string, numpy=array([b'Third', b'Second', b'Second', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: id=84, shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'C'], dtype=object)>, 'embark_town': <tf.Tensor: id=85, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: id=82, shape=(5,), dtype=string, numpy=array([b'y', b'n', b'n', b'y', b'y'], dtype=object)>} tf.Tensor([0 0 1 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.]\n",
      " [28.]\n",
      " [25.]\n",
      " [28.]\n",
      " [28.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 将feature_column 应用到dataset上去\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "for x,y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19.       0.       1.       0.       0.       1.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      10.5      0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 28.       1.       0.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    1.       0.       7.75     1.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [  2.       1.       0.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      21.075    0.       0.       1.       0.       0.\n",
      "    0.       0.       0.       1.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 23.       1.       0.       0.       1.       0.       0.       0.\n",
      "    0.       0.       0.       1.       0.       0.       0.       1.\n",
      "    0.       0.     113.275    1.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.    ]\n",
      " [ 30.       0.       1.       0.       1.       0.       0.       0.\n",
      "    0.       0.       0.       0.       0.       1.       0.       1.\n",
      "    0.       0.      56.9292   0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.    ]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "for x,y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(2,activation=\"softmax\"),\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "             metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运算\n",
    "##### 1.model.fit\n",
    "##### 2.model ->estimator -> train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7422\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7703 - val_loss: 0.4865 - val_accuracy: 0.7461\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7688 - val_loss: 0.5304 - val_accuracy: 0.7383\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7828 - val_loss: 0.5245 - val_accuracy: 0.7305\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7719 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7922 - val_loss: 0.5529 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7703 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7875 - val_loss: 0.5341 - val_accuracy: 0.7266\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7844 - val_loss: 0.5046 - val_accuracy: 0.7461\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7891 - val_loss: 0.4881 - val_accuracy: 0.7461\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7984 - val_loss: 0.4997 - val_accuracy: 0.7539\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.8094 - val_loss: 0.5816 - val_accuracy: 0.7227\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8000 - val_loss: 0.6131 - val_accuracy: 0.7188\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7828 - val_loss: 0.4869 - val_accuracy: 0.7695\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7719 - val_loss: 0.4938 - val_accuracy: 0.7383\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.8078 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7953 - val_loss: 0.5073 - val_accuracy: 0.7461\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7766 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7781 - val_loss: 0.4859 - val_accuracy: 0.7461\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7891 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7781 - val_loss: 0.4814 - val_accuracy: 0.7617\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7937 - val_loss: 0.5062 - val_accuracy: 0.7578\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.8031 - val_loss: 0.5080 - val_accuracy: 0.7617\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7719 - val_loss: 0.4864 - val_accuracy: 0.7578\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.6539 - val_accuracy: 0.7148\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7937 - val_loss: 0.4855 - val_accuracy: 0.7539\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7844 - val_loss: 0.4770 - val_accuracy: 0.7539\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7766 - val_loss: 0.5791 - val_accuracy: 0.7070\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7922 - val_loss: 0.5727 - val_accuracy: 0.7422\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7781 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8125 - val_loss: 0.4831 - val_accuracy: 0.7578\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7984 - val_loss: 0.5241 - val_accuracy: 0.7539\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.8016 - val_loss: 0.5206 - val_accuracy: 0.7422\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7891 - val_loss: 0.4900 - val_accuracy: 0.7461\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7695\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7937 - val_loss: 0.4914 - val_accuracy: 0.7539\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.8000 - val_loss: 0.5187 - val_accuracy: 0.7422\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7953 - val_loss: 0.5020 - val_accuracy: 0.7773\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7891 - val_loss: 0.4884 - val_accuracy: 0.7461\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8063 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7937 - val_loss: 0.5151 - val_accuracy: 0.7461\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8063 - val_loss: 0.4822 - val_accuracy: 0.7578\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7797 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7922 - val_loss: 0.4987 - val_accuracy: 0.7539\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7859 - val_loss: 0.4836 - val_accuracy: 0.7578\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7859 - val_loss: 0.4803 - val_accuracy: 0.7617\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7922 - val_loss: 0.4815 - val_accuracy: 0.7539\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7922 - val_loss: 0.5392 - val_accuracy: 0.7461\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8078 - val_loss: 0.5389 - val_accuracy: 0.7148\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7539\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7906 - val_loss: 0.5306 - val_accuracy: 0.7266\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7750 - val_loss: 0.4881 - val_accuracy: 0.7578\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7969 - val_loss: 0.5674 - val_accuracy: 0.7383\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7844 - val_loss: 0.5109 - val_accuracy: 0.7383\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8297 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7547 - val_loss: 0.5384 - val_accuracy: 0.7148\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8156 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7906 - val_loss: 0.5104 - val_accuracy: 0.7695\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7766 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7875 - val_loss: 0.5438 - val_accuracy: 0.7031\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8031 - val_loss: 0.5975 - val_accuracy: 0.7344\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7484 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7953 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7703 - val_loss: 0.5432 - val_accuracy: 0.7227\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7953 - val_loss: 0.4927 - val_accuracy: 0.7578\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7781 - val_loss: 0.5285 - val_accuracy: 0.7227\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8109 - val_loss: 0.4914 - val_accuracy: 0.7539\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7703 - val_loss: 0.4859 - val_accuracy: 0.7578\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7891 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7922 - val_loss: 0.4995 - val_accuracy: 0.7734\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7875 - val_loss: 0.5392 - val_accuracy: 0.7422\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7844 - val_loss: 0.4744 - val_accuracy: 0.7461\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8141 - val_loss: 0.6061 - val_accuracy: 0.7227\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7891 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7844 - val_loss: 0.5078 - val_accuracy: 0.7461\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7953 - val_loss: 0.5444 - val_accuracy: 0.7383\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8047 - val_loss: 0.5025 - val_accuracy: 0.7617\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7953 - val_loss: 0.4842 - val_accuracy: 0.7578\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7781 - val_loss: 0.4901 - val_accuracy: 0.7383\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7828 - val_loss: 0.4820 - val_accuracy: 0.7539\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.8047 - val_loss: 0.4954 - val_accuracy: 0.7734\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8063 - val_loss: 0.5007 - val_accuracy: 0.7539\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7937 - val_loss: 0.4959 - val_accuracy: 0.7422\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7797 - val_loss: 0.5328 - val_accuracy: 0.7461\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7766 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7859 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7984 - val_loss: 0.5355 - val_accuracy: 0.7227\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8109 - val_loss: 0.4862 - val_accuracy: 0.7539\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8031 - val_loss: 0.5879 - val_accuracy: 0.6719\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7891 - val_loss: 0.4766 - val_accuracy: 0.7539\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8078 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7891 - val_loss: 0.5254 - val_accuracy: 0.7305\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7969 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8016 - val_loss: 0.4859 - val_accuracy: 0.7461\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8109 - val_loss: 0.4784 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7855 - val_loss: 0.4919 - val_accuracy: 0.7539\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-68ca11383289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m                    )\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m   \u001b[1;31m# End of an epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m   \u001b[0maggregator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Empty training data.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "# 1.model.fit\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "train_dataset = make_dataset(train_df, y_train, epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval,epochs = 1, shuffle= False)\n",
    "history = model.fit(train_dataset,validation_data = eval_dataset,\n",
    "                    steps_per_epoch = 20,\n",
    "                    validation_steps =8,\n",
    "                    epochs = 100\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\12399\\AppData\\Local\\Temp\\tmpq4564zi0\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\12399\\\\AppData\\\\Local\\\\Temp\\\\tmpq4564zi0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C976BC0B00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From D:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-cb6c3fc41146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 2.return a.(features, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#          b.dataset => (feature, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m estimator.train(input_fn = lambda: make_dataset(\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             ))\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1190\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m       \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[1;32m--> 419\u001b[1;33m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[0;32m    420\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\tensorflow200\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[0;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[1;32m--> 987\u001b[1;33m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# 2.model ->estimator -> train\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# 1.function\n",
    "# 2.return a.(features, label)\n",
    "#          b.dataset => (feature, label)\n",
    "estimator.train(input_fn = lambda: make_dataset(\n",
    "                train_df, y_train, epochs=100\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
