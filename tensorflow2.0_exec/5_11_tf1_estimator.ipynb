{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    tf1.0 estimator\\n    使用预定义的estimator\\n        BaselineClassifier\\n        LinearClassifier\\n        DNNClassifier\\n    Tf.feature_column 做特征工程\\n    \\n    \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    tf1.0 自定义estimator\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "sys.version_info(major=3, minor=6, micro=2, releaselevel='final', serial=0)\n",
      "matplotlib 3.0.3\n",
      "numpy 1.16.2\n",
      "pandas 0.24.2\n",
      "sklearn 0.20.3\n",
      "tensorflow 1.13.1\n",
      "tensorflow._api.v1.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "    sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0  male  35.0                   0      0   8.0500  Third  unknown   \n",
      "1  male  54.0                   0      0  51.8625  First        E   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval =  eval_df.pop(\"survived\")\n",
    "\n",
    "print(train_df.head(2))\n",
    "print(eval_df.head(2))\n",
    "print(y_train.head(2))\n",
    "print(y_eval.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_column\n",
    "categorical_columns = [\"sex\", \"n_siblings_spouses\", \"parch\", \n",
    "                       \"class\", \"deck\", \"embark_town\", \"alone\"]\n",
    "numeric_columns = [\"age\",\"fare\" ]\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    # 离散特征作成one-hot编码\n",
    "    onehot_describe = tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            categorical_column, vocab))\n",
    "    feature_columns.append(onehot_describe)\n",
    "    \n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(numeric_column, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10,# 数据集遍历多少次 ， \n",
    "                 shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "         (dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001616B079BE0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.68901914, step = 1\n",
      "INFO:tensorflow:global_step/sec: 378.902\n",
      "INFO:tensorflow:loss = 0.53562534, step = 101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.069\n",
      "INFO:tensorflow:loss = 0.3775941, step = 201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.715\n",
      "INFO:tensorflow:loss = 0.49348205, step = 301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.264\n",
      "INFO:tensorflow:loss = 0.36416382, step = 401 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.673\n",
      "INFO:tensorflow:loss = 0.27449453, step = 501 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.45\n",
      "INFO:tensorflow:loss = 0.6135023, step = 601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.272\n",
      "INFO:tensorflow:loss = 0.43066955, step = 701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.286\n",
      "INFO:tensorflow:loss = 0.37766752, step = 801 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.248\n",
      "INFO:tensorflow:loss = 0.29463613, step = 901 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.93\n",
      "INFO:tensorflow:loss = 0.15671581, step = 1001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.123\n",
      "INFO:tensorflow:loss = 0.53142726, step = 1101 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.28\n",
      "INFO:tensorflow:loss = 0.34342664, step = 1201 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.253\n",
      "INFO:tensorflow:loss = 0.3749357, step = 1301 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.101\n",
      "INFO:tensorflow:loss = 0.28243244, step = 1401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.06\n",
      "INFO:tensorflow:loss = 0.40793604, step = 1501 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.668\n",
      "INFO:tensorflow:loss = 0.52522266, step = 1601 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.226\n",
      "INFO:tensorflow:loss = 0.1889992, step = 1701 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.238\n",
      "INFO:tensorflow:loss = 0.50165427, step = 1801 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.256\n",
      "INFO:tensorflow:loss = 0.23438232, step = 1901 (0.143 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.57253355.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1616b079908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"customized_estimator\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # model runtime state: train; eval; predict\n",
    "    input_for_next_layer = tf.feature_column.input_layer(\n",
    "        features, params[\"feature_column\"])\n",
    "    for n_unit in params[\"hidden_units\"]:\n",
    "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
    "                                              units = n_unit,\n",
    "                                              activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(input_for_next_layer,\n",
    "                            params[\"n_classes\"],\n",
    "                            activation = None)  \n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\":predicted_classes[:, tf.newaxis],\n",
    "            \"probabilities\": tf.nn.softmax(logits),\n",
    "            \"logits\":logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode,\n",
    "                                      predictions = predictions)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels,\n",
    "                                                 logits = logits)\n",
    "    accuracy = tf.metrics.accuracy(labels = labels, \n",
    "                                   predictions = predicted_classes,\n",
    "                                   name = \"acc_op\")\n",
    "    metrics = {\"accuracy\":accuracy}\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
    "                                          eval_metric_ops=metrics)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss, \n",
    "                                  global_step = tf.train.get_global_step())\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
    "                                          train_op = train_op)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn, \n",
    "    model_dir=output_dir, \n",
    "    params= {\n",
    "        \"feature_column\": feature_columns,\n",
    "        \"hidden_units\": [100,100],\n",
    "        \"n_classes\":2\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-09T14:52:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From D:\\software\\Anaconda\\envs\\tensorflow100\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from customized_estimator\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-09-14:52:05\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.79545456, global_step = 1960, loss = 0.49870354\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79545456, 'global_step': 1960, 'loss': 0.49870354}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(lambda:make_dataset(eval_df, y_eval, epochs = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env: tensorflow100]",
   "language": "python",
   "name": "tensorflow100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
